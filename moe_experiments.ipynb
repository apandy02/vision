{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "from src.resnet import ResNet\n",
    "import torch \n",
    "from torch import nn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([4.5399e-05, 2.1269e+00, 3.0486e+00])"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tensor_a = torch.tensor([-10., 2., 3.])\n",
    "\n",
    "torch.nn.functional.softplus(tensor_a)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.return_types.topk(\n",
       "values=tensor([3.]),\n",
       "indices=tensor([2]))"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "top_k = torch.topk(tensor_a, 1)\n",
    "top_k"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([-inf, -inf, 3.])"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tensor_a.masked_fill_(tensor_a != top_k.values, -float('inf'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "class MoEGate(nn.Module):\n",
    "    \"\"\"\n",
    "    Mixture of Experts (MoE) Gate module.\n",
    "    \"\"\"\n",
    "    def __init__(self, input_channels: int, gate_dim: int, k: int, bias: bool = False) -> None:\n",
    "        \"\"\"\n",
    "        Args:\n",
    "            input_channels (int): Number of input channels.\n",
    "            gate_dim (int): Dimensionality of the gate.\n",
    "            k (int): Number of top gate values to keep.\n",
    "            bias (bool, optional): Whether or not to add a bias term in the linear layers.\n",
    "        \"\"\"\n",
    "        super().__init__(input_channels, gate_dim)\n",
    "\n",
    "        self.w_gate = nn.Linear(input_channels, gate_dim, bias=bias)\n",
    "        self.w_noise = nn.Linear(input_channels, gate_dim, bias=bias)\n",
    "\n",
    "        self.k = k\n",
    "    \n",
    "    def forward(self, x: torch.tensor) -> torch.tensor:\n",
    "        \"\"\"\n",
    "        Computes the output of the MoE gate by computing the outputs of two linear layers,\n",
    "        adding noise to one of them, and keeping only the top k largest values.\n",
    "\n",
    "        Args:\n",
    "            x (torch.tensor): Input tensor.\n",
    "\n",
    "        Returns:\n",
    "            torch.tensor: Output of the MoE gate.\n",
    "        \"\"\"\n",
    "        h_noise = self.w_noise(x)\n",
    "        noise = torch.randn_like(h_noise).to(x.device)\n",
    "        h_noise = torch.nn.functional.softplus(h_noise).dot(noise)\n",
    "\n",
    "        h_gate = self.w_gate(x)\n",
    "        h = h_gate + h_noise\n",
    "\n",
    "        top_k = torch.topk(h, k=self.k, dim=-1)\n",
    "        output = h.masked_fill_(h != top_k.values, -float('inf'))\n",
    "\n",
    "        return output\n",
    "\n",
    "        \n",
    "\n",
    "class MoE(nn.Module):\n",
    "    def __init__(\n",
    "        self,\n",
    "        num_experts: int,\n",
    "        input_channels: int,\n",
    "        num_classes: int,\n",
    "        channel_sizes: list[int],\n",
    "        gate_dim: int\n",
    "    ) -> None:\n",
    "        \"\"\"\n",
    "        Dummy mixture of experts model.\n",
    "        \"\"\"\n",
    "        super().__init__()\n",
    "        self.num_experts = num_experts\n",
    "        experts = []\n",
    "        for _ in range(num_experts):\n",
    "            experts.append(\n",
    "                ResNet(input_channels, num_channels=num_classes, filters=channel_sizes)\n",
    "            )\n",
    "        \n",
    "        self.experts = nn.ModuleList(experts)\n",
    "\n",
    "        self.gate = MoEGate(input_channels=input_channels, gate_dim=gate_dim)\n",
    "        \n",
    "    \n",
    "    def forward(self, x: torch.tensor):\n",
    "        pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.15"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from src.resnet import ResNet\n",
    "import torch \n",
    "from torch import nn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([4.5399e-05, 2.1269e+00, 3.0486e+00])"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tensor_a = torch.tensor([-10., 2., 3.])\n",
    "\n",
    "torch.nn.functional.softplus(tensor_a)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.return_types.topk(\n",
       "values=tensor([3.]),\n",
       "indices=tensor([2]))"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "top_k = torch.topk(tensor_a, 1)\n",
    "top_k"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([-inf, -inf, 3.])"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tensor_a.masked_fill_(tensor_a != top_k.values, -float('inf'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "ename": "SyntaxError",
     "evalue": "invalid syntax (2975407303.py, line 62)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;36m  Cell \u001b[0;32mIn[6], line 62\u001b[0;36m\u001b[0m\n\u001b[0;31m    resnet.del()\u001b[0m\n\u001b[0m           ^\u001b[0m\n\u001b[0;31mSyntaxError\u001b[0m\u001b[0;31m:\u001b[0m invalid syntax\n"
     ]
    }
   ],
   "source": [
    "class MoEGate(nn.Module):\n",
    "    \"\"\"\n",
    "    Mixture of Experts (MoE) Gate module.\n",
    "    \"\"\"\n",
    "    def __init__(self, input_channels: int, gate_dim: int, k: int, bias: bool = False) -> None:\n",
    "        \"\"\"\n",
    "        Args:\n",
    "            input_channels (int): Number of input channels.\n",
    "            gate_dim (int): Dimensionality of the gate.\n",
    "            k (int): Number of top gate values to keep.\n",
    "            bias (bool, optional): Whether or not to add a bias term in the linear layers.\n",
    "        \"\"\"\n",
    "        super().__init__(input_channels, gate_dim)\n",
    "\n",
    "        self.w_gate = nn.Linear(input_channels, gate_dim, bias=bias)\n",
    "        self.w_noise = nn.Linear(input_channels, gate_dim, bias=bias)\n",
    "\n",
    "        self.k = k\n",
    "    \n",
    "    def forward(self, x: torch.tensor) -> torch.tensor:\n",
    "        \"\"\"\n",
    "        Computes the output of the MoE gate by computing the outputs of two linear layers,\n",
    "        adding noise to one of them, and keeping only the top k largest values.\n",
    "\n",
    "        Args:\n",
    "            x (torch.tensor): Input tensor.\n",
    "\n",
    "        Returns:\n",
    "            torch.tensor: Output of the MoE gate.\n",
    "        \"\"\"\n",
    "        h_noise = self.w_noise(x)\n",
    "        noise = torch.randn_like(h_noise).to(x.device)\n",
    "        h_noise = torch.nn.functional.softplus(h_noise).dot(noise)\n",
    "\n",
    "        h_gate = self.w_gate(x)\n",
    "        h = h_gate + h_noise\n",
    "\n",
    "        top_k = torch.topk(h, k=self.k, dim=-1)\n",
    "        output = h.masked_fill_(h != top_k.values, -float('inf'))\n",
    "\n",
    "        return output\n",
    "\n",
    "        \n",
    "\n",
    "class MoE(nn.Module):\n",
    "    def __init__(\n",
    "        self,\n",
    "        num_experts: int,\n",
    "        input_channels: int,\n",
    "        num_classes: int,\n",
    "        channel_sizes: list[int],\n",
    "        gate_dim: int,\n",
    "        dropout: float\n",
    "    ) -> None:\n",
    "        \"\"\"\n",
    "        Dummy mixture of experts model.\n",
    "        \"\"\"\n",
    "        super().__init__()\n",
    "        self.num_experts = num_experts\n",
    "        experts = []\n",
    "        for _ in range(num_experts):\n",
    "            resnet = ResNet(input_channels, num_channels=num_classes, filters=channel_sizes, dropout=dropout)\n",
    "            \n",
    "            # delete last few layers to extract feature maps\n",
    "            del resnet.linear\n",
    "            del resnet.flatten\n",
    "            del resnet.avgpool\n",
    "            del resnet.dropout\n",
    "            experts.append(resnet)\n",
    "        \n",
    "        self.experts = nn.ModuleList(experts)\n",
    "\n",
    "        self.gate = MoEGate(input_channels=input_channels, gate_dim=gate_dim)\n",
    "\n",
    "        self.linear = nn.Linear(channel_sizes[-1], num_classes)\n",
    "        self.dropout = nn.Dropout(p=dropout)\n",
    "        self.avgpool = nn.AdaptiveAvgPool2d((1, 1))\n",
    "        self.flatten = nn.Flatten()\n",
    "        \n",
    "        \n",
    "    \n",
    "    def forward(self, x: torch.tensor):\n",
    "        \"\"\"\n",
    "        The forward pass of the MoE model.\n",
    "        \"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "resnet = ResNet(num_channels=3, num_classes=10, filters=[32, 64, 128])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ResNet(\n",
       "  (res_layers): Sequential(\n",
       "    (0): ResBlock(\n",
       "      (norm1): Sequential(\n",
       "        (0): GroupNorm(1, 3, eps=1e-05, affine=True)\n",
       "        (1): ReLU()\n",
       "      )\n",
       "      (conv1): Conv2d(3, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "      (conv2): Sequential(\n",
       "        (0): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (1): GroupNorm(1, 32, eps=1e-05, affine=True)\n",
       "      )\n",
       "      (activation): ReLU()\n",
       "      (idconv): Conv2d(3, 32, kernel_size=(1, 1), stride=(1, 1))\n",
       "      (avgpool): Identity()\n",
       "      (dropout): Dropout(p=0.2, inplace=False)\n",
       "    )\n",
       "    (1): ResBlock(\n",
       "      (norm1): Sequential(\n",
       "        (0): GroupNorm(1, 32, eps=1e-05, affine=True)\n",
       "        (1): ReLU()\n",
       "      )\n",
       "      (conv1): Conv2d(32, 64, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1))\n",
       "      (conv2): Sequential(\n",
       "        (0): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (1): GroupNorm(1, 64, eps=1e-05, affine=True)\n",
       "      )\n",
       "      (activation): ReLU()\n",
       "      (idconv): Conv2d(32, 64, kernel_size=(1, 1), stride=(1, 1))\n",
       "      (avgpool): AvgPool2d(kernel_size=2, stride=2, padding=0)\n",
       "      (dropout): Dropout(p=0.2, inplace=False)\n",
       "    )\n",
       "    (2): ResBlock(\n",
       "      (norm1): Sequential(\n",
       "        (0): GroupNorm(1, 64, eps=1e-05, affine=True)\n",
       "        (1): ReLU()\n",
       "      )\n",
       "      (conv1): Conv2d(64, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1))\n",
       "      (conv2): Sequential(\n",
       "        (0): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "        (1): GroupNorm(1, 128, eps=1e-05, affine=True)\n",
       "      )\n",
       "      (activation): ReLU()\n",
       "      (idconv): Conv2d(64, 128, kernel_size=(1, 1), stride=(1, 1))\n",
       "      (avgpool): AvgPool2d(kernel_size=2, stride=2, padding=0)\n",
       "      (dropout): Dropout(p=0.2, inplace=False)\n",
       "    )\n",
       "  )\n",
       "  (dropout): Dropout(p=0.2, inplace=False)\n",
       ")"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "resnet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.15"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

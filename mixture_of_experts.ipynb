{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [],
   "source": [
    "from src.resnet import ResNet\n",
    "import torch \n",
    "from torch import nn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([4.5399e-05, 2.1269e+00, 3.0486e+00])"
      ]
     },
     "execution_count": 89,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tensor_a = torch.tensor([-10., 2., 3.])\n",
    "\n",
    "torch.nn.functional.softplus(tensor_a)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.return_types.topk(\n",
       "values=tensor([3.]),\n",
       "indices=tensor([2]))"
      ]
     },
     "execution_count": 90,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "top_k = torch.topk(tensor_a, 1)\n",
    "top_k"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([-inf, -inf, 3.])"
      ]
     },
     "execution_count": 91,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tensor_a.masked_fill_(tensor_a != top_k.values, -float('inf'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [],
   "source": [
    "class MoEGate(nn.Module):\n",
    "    \"\"\"\n",
    "    Mixture of Experts (MoE) Gate module.\n",
    "    \"\"\"\n",
    "    def __init__(self, input_size: int, gate_dim: int, k: int, bias: bool = False) -> None:\n",
    "        \"\"\"\n",
    "        Args:\n",
    "            input_size (int): Number of input channels.\n",
    "            gate_dim (int): Dimensionality of the gate.\n",
    "            k (int): Number of top gate values to keep.\n",
    "            bias (bool, optional): Whether or not to add a bias term in the linear layers.\n",
    "        \"\"\"\n",
    "        super().__init__()\n",
    "\n",
    "        self.w_gate = nn.Linear(input_size, gate_dim, bias=bias)\n",
    "        self.w_noise = nn.Linear(input_size, gate_dim, bias=bias)\n",
    "\n",
    "        self.k = k\n",
    "    \n",
    "    def forward(self, x: torch.tensor) -> torch.tensor:\n",
    "        \"\"\"\n",
    "        Computes the output of the MoE gate by computing the outputs of two linear layers,\n",
    "        adding noise to one of them, and keeping only the top k largest values.\n",
    "\n",
    "        Args:\n",
    "            x (torch.tensor): Input tensor.\n",
    "\n",
    "        Returns:\n",
    "            torch.tensor: Output of the MoE gate.\n",
    "        \"\"\"\n",
    "        h_noise = self.w_noise(x)\n",
    "        noise = torch.randn_like(h_noise).to(x.device)\n",
    "        h_noise = torch.nn.functional.softplus(h_noise)\n",
    "        h_noise = h_noise * noise\n",
    "\n",
    "        h_gate = self.w_gate(x)\n",
    "        h = h_gate + h_noise\n",
    "\n",
    "        top_k = torch.topk(h, k=self.k, dim=-1)\n",
    "        \n",
    "        output = h.masked_fill_(~torch.isin(h, top_k.values), -float('inf'))\n",
    "\n",
    "        return output\n",
    "\n",
    "        \n",
    "\n",
    "class MoE(nn.Module):\n",
    "    def __init__(\n",
    "        self,\n",
    "        num_experts: int,\n",
    "        input_size: int,\n",
    "        input_channels: int,\n",
    "        num_classes: int,\n",
    "        channel_sizes: list[int],\n",
    "        gate_dim: int,\n",
    "        dropout: float,\n",
    "        k: int\n",
    "    ) -> None:\n",
    "        \"\"\"\n",
    "        Dummy mixture of experts model.\n",
    "        \"\"\"\n",
    "        super().__init__()\n",
    "        self.num_experts = num_experts\n",
    "        experts = []\n",
    "\n",
    "        self.gate = MoEGate(input_size=input_size, gate_dim=gate_dim, k=k)\n",
    "\n",
    "        for _ in range(num_experts):\n",
    "            resnet = ResNet(num_channels=input_channels, num_classes=num_classes, filters=channel_sizes, dropout=dropout)\n",
    "            experts.append(resnet)\n",
    "            del resnet.linear\n",
    "            del resnet.flatten\n",
    "            del resnet.avgpool\n",
    "            del resnet.dropout\n",
    "        \n",
    "        self.experts = nn.ModuleList(experts)\n",
    "        self.linear = nn.Linear(channel_sizes[-1], num_classes)\n",
    "        self.dropout = nn.Dropout(p=dropout)\n",
    "        self.avgpool = nn.AdaptiveAvgPool2d((1, 1))\n",
    "        self.flatten = nn.Flatten()\n",
    "        \n",
    "        \n",
    "    \n",
    "    def forward(self, x: torch.tensor):\n",
    "        \"\"\"\n",
    "        The forward pass of the MoE model.\n",
    "        \"\"\"\n",
    "        gate_out = self.gate(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [],
   "source": [
    "moe = MoE(2, 3072, 3, 10, [8,16,32], 8, 0.1, 2)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "MoE(\n",
       "  (gate): MoEGate(\n",
       "    (w_gate): Linear(in_features=3072, out_features=8, bias=False)\n",
       "    (w_noise): Linear(in_features=3072, out_features=8, bias=False)\n",
       "  )\n",
       "  (experts): ModuleList(\n",
       "    (0-1): 2 x ResNet(\n",
       "      (res_layers): Sequential(\n",
       "        (0): ResBlock(\n",
       "          (norm1): Sequential(\n",
       "            (0): GroupNorm(1, 3, eps=1e-05, affine=True)\n",
       "            (1): ReLU()\n",
       "          )\n",
       "          (conv1): Conv2d(3, 8, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "          (conv2): Sequential(\n",
       "            (0): Conv2d(8, 8, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "            (1): GroupNorm(1, 8, eps=1e-05, affine=True)\n",
       "          )\n",
       "          (activation): ReLU()\n",
       "          (idconv): Conv2d(3, 8, kernel_size=(1, 1), stride=(1, 1))\n",
       "          (avgpool): Identity()\n",
       "          (dropout): Dropout(p=0.2, inplace=False)\n",
       "        )\n",
       "        (1): ResBlock(\n",
       "          (norm1): Sequential(\n",
       "            (0): GroupNorm(1, 8, eps=1e-05, affine=True)\n",
       "            (1): ReLU()\n",
       "          )\n",
       "          (conv1): Conv2d(8, 16, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1))\n",
       "          (conv2): Sequential(\n",
       "            (0): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "            (1): GroupNorm(1, 16, eps=1e-05, affine=True)\n",
       "          )\n",
       "          (activation): ReLU()\n",
       "          (idconv): Conv2d(8, 16, kernel_size=(1, 1), stride=(1, 1))\n",
       "          (avgpool): AvgPool2d(kernel_size=2, stride=2, padding=0)\n",
       "          (dropout): Dropout(p=0.1, inplace=False)\n",
       "        )\n",
       "        (2): ResBlock(\n",
       "          (norm1): Sequential(\n",
       "            (0): GroupNorm(1, 16, eps=1e-05, affine=True)\n",
       "            (1): ReLU()\n",
       "          )\n",
       "          (conv1): Conv2d(16, 32, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1))\n",
       "          (conv2): Sequential(\n",
       "            (0): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "            (1): GroupNorm(1, 32, eps=1e-05, affine=True)\n",
       "          )\n",
       "          (activation): ReLU()\n",
       "          (idconv): Conv2d(16, 32, kernel_size=(1, 1), stride=(1, 1))\n",
       "          (avgpool): AvgPool2d(kernel_size=2, stride=2, padding=0)\n",
       "          (dropout): Dropout(p=0.1, inplace=False)\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "  )\n",
       "  (linear): Linear(in_features=32, out_features=10, bias=True)\n",
       "  (dropout): Dropout(p=0.1, inplace=False)\n",
       "  (avgpool): AdaptiveAvgPool2d(output_size=(1, 1))\n",
       "  (flatten): Flatten(start_dim=1, end_dim=-1)\n",
       ")"
      ]
     },
     "execution_count": 94,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "moe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "top_k: torch.return_types.topk(\n",
      "values=tensor([[1.6061, 1.4496]], grad_fn=<TopkBackward0>),\n",
      "indices=tensor([[7, 1]]))\n",
      "h: tensor([[-1.1639,  1.4496,  0.3324,  0.1293, -0.6456, -0.8210,  0.7208,  1.6061]],\n",
      "       grad_fn=<AddBackward0>)\n",
      "output: tensor([[  -inf, 1.4496,   -inf,   -inf,   -inf,   -inf,   -inf, 1.6061]],\n",
      "       grad_fn=<MaskedFillBackward0>)\n",
      "output: tensor([[0.0000, 0.4610, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.5390]],\n",
      "       grad_fn=<SoftmaxBackward0>)\n"
     ]
    }
   ],
   "source": [
    "x = torch.randn(1, 3, 32, 32)\n",
    "x = x.view(x.shape[0], -1)\n",
    "moe(x)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.15"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

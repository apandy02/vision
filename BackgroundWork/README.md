**Background work** 

This sub-directory contains code to some of my "nuts and bolts" versions of machine learning concepts. I build a linear regression model with vanilla 
gradient descent, one with stochastic gradient descent, and a logisitic regression model with both flavors of gradient descent as well. 

I did in the past write out SGD w/ Nesterov and Polyak momenta, as well as more basic LTI optimization such as the Richardson iteration. I may have lost 
my code for most of my nuts and bolts work, but this is what I could retrieve. 

Everything here is done at a lower abstraction level (coded in numpy) to help me build a stronger intuition. 

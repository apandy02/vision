{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Denoising Diffusion Probabilistic Models\n",
    "\n",
    "In this notebook, we'll implement the Denoising Diffusion Probabilistic Model (DDPM) proposed in the paper [Denoising Diffusion Probabilistic Models](https://arxiv.org/abs/2006.11239) from scratch using PyTorch. We'll implement the U-Net model, the forward and reverse diffusion processes, the training loop and the sampling process."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 163,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch \n",
    "import torch.nn as nn\n",
    "import matplotlib.pyplot as plt\n",
    "import math"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## UNet\n",
    "\n",
    "The U-net is implemented as in the original paper. It's been divided into blocks to make it more modular and easier to work with. The \"downblock\" consists of a series of convolutional layers, each followed by a maxpooling layer. The \"upblock\" consists of a convolutional layer followed by a transpose convolutional layer. The bottom-most conv block is implemented separately and is different from the rest of the blocks."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 164,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ConvBlock(nn.Module):\n",
    "    \"\"\"\n",
    "    Convolutional block with two convolutional layers.\n",
    "    The first conv layer changes the number of channels\n",
    "    The second maintains the number of channels\n",
    "    \"\"\"\n",
    "    def __init__(self, in_channels, out_channels, kernel_size=3, stride=1):\n",
    "        super(ConvBlock, self).__init__()\n",
    "        self.conv1 = nn.Conv2d(in_channels, out_channels, kernel_size, stride)\n",
    "        self.relu = nn.ReLU(inplace=True)\n",
    "        self.conv2 = nn.Conv2d(out_channels, out_channels, kernel_size, stride)\n",
    "    \n",
    "    def forward(self, x):\n",
    "        x = self.relu(self.conv1(x))\n",
    "        return self.relu(self.conv2(x))\n",
    "    \n",
    "class DownBlock(nn.Module):\n",
    "    \"\"\"\n",
    "    Downampling (left) side of the UNet.\n",
    "    Excludes the bottom-most conv block.\n",
    "    \"\"\"\n",
    "    def __init__(self, filters, in_channels):\n",
    "        super(DownBlock, self).__init__()\n",
    "        conv_blocks = [ConvBlock(in_channels, filters[0])]\n",
    "        for i in range(1, len(filters)):\n",
    "            conv_blocks.append(ConvBlock(filters[i-1], filters[i]))\n",
    "\n",
    "        self.conv_blocks = nn.Sequential(*conv_blocks)\n",
    "        self.maxpool = nn.MaxPool2d(kernel_size=2, stride=2)\n",
    "\n",
    "    def forward(self, x):\n",
    "        residual_outputs = []\n",
    "        for conv_block in self.conv_blocks:\n",
    "            x = conv_block(x)\n",
    "            residual_outputs.append(x)\n",
    "            x = self.maxpool(x)\n",
    "\n",
    "        return residual_outputs, x\n",
    "\n",
    "class UpBlock(nn.Module):\n",
    "    \"\"\"\n",
    "    Upsampling (right) side of the UNet.\n",
    "    \"\"\"\n",
    "    def __init__(self, filters):\n",
    "        super(UpBlock, self).__init__()\n",
    "        layers = []\n",
    "        for i in range(len(filters) - 2):\n",
    "            layers.append(\n",
    "                nn.Sequential(\n",
    "                    ConvBlock(filters[i], filters[i+1]), \n",
    "                    nn.ConvTranspose2d(filters[i+1], filters[i+1]//2, 2, stride=2)\n",
    "                )\n",
    "            )\n",
    "        \n",
    "        layers.append(ConvBlock(filters[-2], filters[-1]))\n",
    "        self.layers = nn.Sequential(*layers)\n",
    "    \n",
    "    def forward(self, x, residual_outputs):\n",
    "        for i in range(len(self.layers)):\n",
    "            print(f\"i: {i}\")\n",
    "            residual = residual_outputs[-(i+1)]\n",
    "            _, _, h, w = x.shape\n",
    "            residual = residual[:, :, :h, :w]\n",
    "            print(f\"x: {x.shape}, residual: {residual.shape}\")\n",
    "            x = torch.cat([x, residual], dim=1)\n",
    "            x = self.layers[i](x)\n",
    "            print(f\"x: {x.shape}\")\n",
    "        \n",
    "        return x\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 165,
   "metadata": {},
   "outputs": [],
   "source": [
    "db = DownBlock([32, 64, 128], 3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 166,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DownBlock(\n",
       "  (conv_blocks): Sequential(\n",
       "    (0): ConvBlock(\n",
       "      (conv1): Conv2d(3, 32, kernel_size=(3, 3), stride=(1, 1))\n",
       "      (relu): ReLU(inplace=True)\n",
       "      (conv2): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1))\n",
       "    )\n",
       "    (1): ConvBlock(\n",
       "      (conv1): Conv2d(32, 64, kernel_size=(3, 3), stride=(1, 1))\n",
       "      (relu): ReLU(inplace=True)\n",
       "      (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1))\n",
       "    )\n",
       "    (2): ConvBlock(\n",
       "      (conv1): Conv2d(64, 128, kernel_size=(3, 3), stride=(1, 1))\n",
       "      (relu): ReLU(inplace=True)\n",
       "      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1))\n",
       "    )\n",
       "  )\n",
       "  (maxpool): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       ")"
      ]
     },
     "execution_count": 166,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "db"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 167,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([1, 128, 12, 12])"
      ]
     },
     "execution_count": 167,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a = db(torch.randn(1, 3, 128, 128))\n",
    "a[1].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 168,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([1, 32, 124, 124])\n",
      "----------\n",
      "torch.Size([1, 64, 58, 58])\n",
      "----------\n",
      "torch.Size([1, 128, 25, 25])\n",
      "----------\n",
      "torch.Size([1, 128, 12, 12])\n"
     ]
    }
   ],
   "source": [
    "for residual_output in a[0]:\n",
    "    print(residual_output.shape)\n",
    "    print(\"-\"*10)\n",
    "\n",
    "print(a[1].shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 169,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([1, 128, 16, 16])"
      ]
     },
     "execution_count": 169,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bottom_conv = nn.Sequential(ConvBlock(128, 256), nn.ConvTranspose2d(256, 128, 2, stride=2))\n",
    "bottom_conv(a[1]).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 170,
   "metadata": {},
   "outputs": [],
   "source": [
    "up = UpBlock([256, 128, 64, 32])\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 171,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sequential(\n",
      "  (0): ConvBlock(\n",
      "    (conv1): Conv2d(256, 128, kernel_size=(3, 3), stride=(1, 1))\n",
      "    (relu): ReLU(inplace=True)\n",
      "    (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1))\n",
      "  )\n",
      "  (1): ConvTranspose2d(128, 64, kernel_size=(2, 2), stride=(2, 2))\n",
      ")\n",
      "----------\n",
      "Sequential(\n",
      "  (0): ConvBlock(\n",
      "    (conv1): Conv2d(128, 64, kernel_size=(3, 3), stride=(1, 1))\n",
      "    (relu): ReLU(inplace=True)\n",
      "    (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1))\n",
      "  )\n",
      "  (1): ConvTranspose2d(64, 32, kernel_size=(2, 2), stride=(2, 2))\n",
      ")\n",
      "----------\n",
      "ConvBlock(\n",
      "  (conv1): Conv2d(64, 32, kernel_size=(3, 3), stride=(1, 1))\n",
      "  (relu): ReLU(inplace=True)\n",
      "  (conv2): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1))\n",
      ")\n",
      "----------\n"
     ]
    }
   ],
   "source": [
    "for layer in up.layers:\n",
    "    print(layer)\n",
    "    print(\"-\"*10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 172,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([1, 128, 16, 16])"
      ]
     },
     "execution_count": 172,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bottom_out = bottom_conv(a[1])\n",
    "bottom_out.shape\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 173,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "i: 0\n",
      "x: torch.Size([1, 128, 16, 16]), residual: torch.Size([1, 128, 16, 16])\n",
      "x: torch.Size([1, 64, 24, 24])\n",
      "i: 1\n",
      "x: torch.Size([1, 64, 24, 24]), residual: torch.Size([1, 64, 24, 24])\n",
      "x: torch.Size([1, 32, 40, 40])\n",
      "i: 2\n",
      "x: torch.Size([1, 32, 40, 40]), residual: torch.Size([1, 32, 40, 40])\n",
      "x: torch.Size([1, 32, 36, 36])\n"
     ]
    }
   ],
   "source": [
    "up_out = up(bottom_out, a[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 174,
   "metadata": {},
   "outputs": [],
   "source": [
    "class UNet(nn.Module):\n",
    "    def __init__(self, down_filters, in_channels):\n",
    "        super(UNet, self).__init__()\n",
    "        self.down_filters = down_filters\n",
    "        self.down_block = DownBlock(down_filters, in_channels)\n",
    "        \n",
    "        # the bottom-most conv block is different from the rest of the blocks\n",
    "        # in that it doesn't contain a maxpool and upsamples without a residual connection\n",
    "        self.bottom_conv = nn.Sequential(\n",
    "            ConvBlock(down_filters[-1], down_filters[-1]*2), \n",
    "            nn.ConvTranspose2d(down_filters[-1]*2, down_filters[-1], 2, stride=2)\n",
    "        )\n",
    "        \n",
    "        self.up_filters = [down_filters[-1]*2]\n",
    "        self.up_filters.extend(reversed(down_filters))\n",
    "        self.up_block = UpBlock(self.up_filters)\n",
    "\n",
    "    def forward(self, x):\n",
    "        residual_outputs, down_output = self.down_block(x)\n",
    "        bottom_output = self.bottom_conv(down_output)\n",
    "        return self.up_block(bottom_output, residual_outputs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 175,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "i: 0\n",
      "x: torch.Size([1, 128, 16, 16]), residual: torch.Size([1, 128, 16, 16])\n",
      "x: torch.Size([1, 64, 24, 24])\n",
      "i: 1\n",
      "x: torch.Size([1, 64, 24, 24]), residual: torch.Size([1, 64, 24, 24])\n",
      "x: torch.Size([1, 32, 40, 40])\n",
      "i: 2\n",
      "x: torch.Size([1, 32, 40, 40]), residual: torch.Size([1, 32, 40, 40])\n",
      "x: torch.Size([1, 32, 36, 36])\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "torch.Size([1, 32, 36, 36])"
      ]
     },
     "execution_count": 175,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "u_net = UNet([32, 64, 128], 3)\n",
    "a = u_net(torch.randn(1, 3, 128, 128))\n",
    "a.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 180,
   "metadata": {},
   "outputs": [],
   "source": [
    "def alpha_bar(beta):\n",
    "    alpha = 1. - beta\n",
    "    return alpha.cumprod(dim=0)\n",
    "\n",
    "def prepare_batch(x: torch.Tensor, T: int, alpha_bar: torch.Tensor):\n",
    "    \"\"\"\n",
    "    Prepare a batch for training by generating the noise and the noisy image.\n",
    "    \"\"\"\n",
    "    batch_size = x.shape[0]\n",
    "    t = torch.randint(0, T, (batch_size,))\n",
    "    e = torch.randn_like(x)\n",
    "    alpha_bar_t = alpha_bar(t)\n",
    "    alpha_bar_t = alpha_bar_t.view(-1, 1, 1, 1)\n",
    "    noisy_images = alpha_bar_t.sqrt() * x + (1 - alpha_bar_t).sqrt() * e\n",
    "    \n",
    "    return (noisy_images, t), e\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 185,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([15])\n"
     ]
    }
   ],
   "source": [
    "x = torch.randn(15, 3, 128, 128)\n",
    "T = 1000\n",
    "batch_size = x.shape[0]\n",
    "t = torch.randint(0, T, (batch_size,))\n",
    "e = torch.randn_like(x)\n",
    "alpha_bar_t = alpha_bar(t)\n",
    "print(alpha_bar_t.shape)\n",
    "alpha_bar_t = alpha_bar_t.view(-1, 1, 1, 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 184,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([15, 1, 1, 1])"
      ]
     },
     "execution_count": 184,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "alpha_bar_t.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 176,
   "metadata": {},
   "outputs": [],
   "source": [
    "def validate_model(model, valid_loader, loss_fn, all_valid_loss):\n",
    "    model.eval()\n",
    "    valid_loss = []\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        for batch in valid_loader:\n",
    "            x, y = batch\n",
    "            y_pred = model(x)\n",
    "            loss = loss_fn(y_pred, y)\n",
    "            valid_loss.append(loss.item())\n",
    "    \n",
    "    all_valid_loss.append(sum(valid_loss) / len(valid_loss))\n",
    "\n",
    "def plot_loss(all_train_loss, all_valid_loss):\n",
    "    plt.figure(figsize=(10, 5))\n",
    "    plt.plot(all_train_loss, label='Training Loss')\n",
    "    plt.plot(all_valid_loss, label='Validation Loss')\n",
    "    plt.xlabel('Epoch')\n",
    "    plt.ylabel('Loss')\n",
    "    plt.legend()\n",
    "    plt.show()\n",
    "\n",
    "\n",
    "def train_model(model: nn.Module,\n",
    "                optim: torch.optim.Optimizer,\n",
    "                loss_fn,\n",
    "                train_loader,\n",
    "                valid_loader,\n",
    "                scheduler,\n",
    "                epochs=10,\n",
    "                valid_every=1\n",
    "                ):\n",
    "\n",
    "    all_train_loss = []\n",
    "    all_valid_loss = []\n",
    "    \n",
    "    for epoch in range(epochs):\n",
    "        model.train()\n",
    "        train_loss = []\n",
    "        \n",
    "        for batch in train_loader:\n",
    "            x, _ = batch\n",
    "            (noisy_images, t), e = prepare_batch(x, T, alpha_bar_t)\n",
    "            optim.zero_grad()\n",
    "            y_pred = model(noisy_images)\n",
    "            loss = loss_fn(y_pred, e)\n",
    "            loss.backward()\n",
    "            optim.step()\n",
    "            train_loss.append(loss.item())\n",
    "        \n",
    "        all_train_loss.append(sum(train_loss) / len(train_loss))\n",
    "        scheduler.step()\n",
    "        \n",
    "        if epoch % valid_every == 0:\n",
    "            validate_model(model, valid_loader, loss_fn, all_valid_loss)\n",
    "            print(\n",
    "                f\"Epoch {epoch}, Train Loss: {sum(train_loss) / len(train_loss)}, \"\n",
    "                f\"Valid Loss: {all_valid_loss[-1]}\"\n",
    "            )\n",
    "    \n",
    "    plot_loss(all_train_loss, all_valid_loss)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Changes that need to be made to the U-Net for DDPM:\n",
    "1. Swap batch norm with group norm \n",
    "2. Introduce an attention mechanism at each conv block in the down and up blocks\n",
    "3. Create an embedding for the timestep\n",
    "\n",
    "Next, we'll implement these missing features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def scaled_dot_product_attention(q, k, d_k, mask):\n",
    "    scores = torch.matmul(q, k.transpose(-2, -1)) / math.sqrt(d_k)\n",
    "    if mask is True:\n",
    "        mask = torch.tril(torch.ones(scores.shape)).to(q.device)\n",
    "        scores = scores.masked_fill(mask == 0, float('-inf'))\n",
    "    return nn.Softmax(-1)(scores)\n",
    "\n",
    "class Attention(nn.Module):\n",
    "    \"\"\"\n",
    "    Multihead attention class implementation. Can act as self-attention (default, y is None)\n",
    "    or cross attention if y not none\n",
    "    \"\"\"\n",
    "    def __init__(self, d_k, d_model, d_v, dropout, mask) -> None:\n",
    "        super(Attention, self).__init__()\n",
    "        self.d_k, self.d_v, self.d_model = d_k, d_v, d_model\n",
    "        self.query_layer, self.key_layer, self.value_layer = (\n",
    "            nn.Linear(d_model, d_k), \n",
    "            nn.Linear(d_model, d_k), \n",
    "            nn.Linear(d_model, d_v)\n",
    "        )\n",
    "        self.layer_norm = nn.LayerNorm(d_model)\n",
    "        self.concat_projection = nn.Linear(d_v, d_model)\n",
    "        self.dropout = nn.Dropout(dropout)\n",
    "        self.mask = mask\n",
    "\n",
    "    def forward(self, x, y = None):\n",
    "        residual = x\n",
    "        x = self.layer_norm(x)\n",
    "        if y is not None:\n",
    "            k, q, v = y, x, y\n",
    "        else:\n",
    "            k, q, v = x, x, x\n",
    "        \n",
    "        k_len, q_len, v_len, batch_size = k.size(1), q.size(1), v.size(1),  q.size(0)\n",
    "        k = self.key_layer(k).view(batch_size, k_len,  self.d_k)\n",
    "        q = self.query_layer(q).view(batch_size, q_len,  self.d_k)\n",
    "        v = self.value_layer(v).view(batch_size, v_len,  self.d_v)\n",
    "        attention = scaled_dot_product_attention(q.transpose(1, 2), k.transpose(1, 2), self.d_k, self.mask)\n",
    "        output = torch.matmul(attention, v.transpose(1, 2))\n",
    "        output = self.concat_projection(output.transpose(1, 2).contiguous().view(batch_size, q_len, -1))\n",
    "        \n",
    "        return self.dropout(output) + residual"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "fastai",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.15"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

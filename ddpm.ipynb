{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Denoising Diffusion Probabilistic Models\n",
    "\n",
    "In this notebook, we'll implement the Denoising Diffusion Probabilistic Model (DDPM) proposed in the paper [Denoising Diffusion Probabilistic Models](https://arxiv.org/abs/2006.11239) from scratch using PyTorch. We'll implement the U-Net model, the forward and reverse diffusion processes, the training loop and the sampling process."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch \n",
    "import torch.nn as nn\n",
    "import matplotlib.pyplot as plt\n",
    "import math\n",
    "import pickle\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## UNet\n",
    "At the heart of DDPMs is the U-Net model. The U-Net is a symmetrical architecture with an encoder (left) and decoder (right) path. It takes in a noisy image and predicts the amount of noise that was added to it. \n",
    "\n",
    "In the denoising process, the U-Net takes in the noisy image and the timestep and predicts the amount of noise that was added to it. We can then use this prediction to denoise the image by subtracting the predicted noise from the noisy image. In this manner, we gradually transform the noisy image to a clear image. \n",
    "\n",
    "We split the U-net into 3 blocks, Left, Middle and Right.\n",
    "\n",
    "At the root of it all is the conv block. Each layer in the left and the right blocks consists of a series of ConvBlocks followed by a maxpool or an upsample. \n",
    "\n",
    "The convblocks are resnets with group normalization and are imported from src.resnet.py. We changed the original resnets to accept \"timestep embeddings\" that we'll explore later. \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Changes that need to be made to a regular [U-Net](https://arxiv.org/abs/1505.04597) for DDPM:\n",
    "\n",
    "\n",
    "1. Swap batch norm with group norm \n",
    "2. Introduce an attention mechanism at each conv block in the down and up blocks\n",
    "3. Create an embedding for the timestep\n",
    "4. Develop a 2D attention mechanism based on the one used in the text transformer model in [aryamanpandya99/transformers](https://github.com/aryamanpandya99/transformers)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ConvBlock Illustrated\n",
    "\n",
    "The ConvBlock is a resnet with group normalization followed by a 2D multihead attention. We can set the number of resblocks in the ConvBlock as a parameter. \n",
    "\n",
    "# <img src=\"images/convblock.png\" alt=\"ConvBlock Illustrated\" width=\"50%\"/>\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {},
   "outputs": [],
   "source": [
    "from src.resnet import ResBlock\n",
    "\n",
    "\n",
    "class ConvBlock(nn.Module):\n",
    "    def __init__(\n",
    "            self, \n",
    "            in_channels: int, \n",
    "            out_channels: int, \n",
    "            num_layers: int, \n",
    "            num_groups: int = 1, \n",
    "            dropout: float = 0.2, \n",
    "            activation: nn.Module = nn.ReLU,\n",
    "            timestep_emb_dim: int = None\n",
    "            ):\n",
    "        super(ConvBlock, self).__init__()\n",
    "        convs = []\n",
    "        convs.append(\n",
    "            ResBlock(\n",
    "                in_channels, \n",
    "                out_channels, \n",
    "                num_groups=num_groups, \n",
    "                dropout=dropout, \n",
    "                activation=activation,\n",
    "                timestep_emb_dim=timestep_emb_dim\n",
    "            )\n",
    "        )\n",
    "        \n",
    "        for _ in range(num_layers-1):\n",
    "            convs.append(\n",
    "                ResBlock(\n",
    "                    out_channels,\n",
    "                    out_channels, \n",
    "                    num_groups=num_groups, \n",
    "                    dropout=dropout, \n",
    "                    activation=activation,\n",
    "                    timestep_emb_dim=timestep_emb_dim\n",
    "                )\n",
    "            )\n",
    "\n",
    "        self.convs = nn.ModuleList(convs)\n",
    "\n",
    "    def forward(self, x, timestep_emb=None):\n",
    "        for res_block in self.convs:\n",
    "            x = res_block(x, timestep_emb)\n",
    "        \n",
    "        return x"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Changes to the attention mechanism from Attention is all you need\n",
    "\n",
    "- we no longer need a d_model, the internal hidden size is determined by the number of channels which is determined by the convolutional layers leading up to the attention layer.\n",
    "\n",
    "- swap batch norm with group norm\n",
    "\n",
    "- we resize the image to one of shape: (batch_size, num_channels, height * width) so that we can perform multihead attention across the image. This closely mirrors (batch_size, embed_dim, seq_len)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {},
   "outputs": [],
   "source": [
    "def scaled_dot_product_attention(q, k, d_k, mask):\n",
    "    scores = torch.matmul(q, k.transpose(-2, -1)) / math.sqrt(d_k)\n",
    "    if mask is True:\n",
    "        mask = torch.tril(torch.ones(scores.shape)).to(q.device)\n",
    "        scores = scores.masked_fill(mask == 0, float('-inf'))\n",
    "    return nn.Softmax(-1)(scores)\n",
    "\n",
    "class Attention(nn.Module):\n",
    "    \"\"\"\n",
    "    Multihead attention.\n",
    "    \"\"\"\n",
    "    def __init__(self,\n",
    "                 d_k: int, \n",
    "                 dropout: float, \n",
    "                 num_heads: int, \n",
    "                 num_channels: int,\n",
    "                 num_groups: int = 8,\n",
    "                 mask: bool = False\n",
    "                 ):\n",
    "        super(Attention, self).__init__()\n",
    "        self.d_k, self.num_heads = d_k, num_heads\n",
    "        self.query_projection, self.key_projection, self.value_projection = (\n",
    "            nn.Linear(num_channels, num_heads* d_k),\n",
    "            nn.Linear(num_channels, num_heads* d_k), \n",
    "            nn.Linear(num_channels, num_heads*d_k)\n",
    "        )\n",
    "        self.layer_norm = nn.LayerNorm(num_channels)\n",
    "        self.output_layer = nn.Linear(num_heads*d_k, num_channels)\n",
    "        self.dropout = nn.Dropout(dropout)\n",
    "        self.mask = mask\n",
    "        self.num_channels = num_channels\n",
    "\n",
    "    def forward(self, x, y = None):\n",
    "        \n",
    "        batch_size, n_channels, height, width = x.shape\n",
    "        x = x.view(batch_size, n_channels, height * width).permute(0, 2, 1)\n",
    "        residual = x\n",
    "        x = self.layer_norm(x)\n",
    "        \n",
    "        if y is not None:\n",
    "            k, q, v = y, x, y\n",
    "        else:\n",
    "            k, q, v = x, x, x\n",
    "        \n",
    "        k_len, q_len, v_len, batch_size = k.size(1), q.size(1), v.size(1),  q.size(0)\n",
    "        \n",
    "        k = self.key_projection(k).view(batch_size, k_len,  self.num_heads, self.d_k)\n",
    "        q = self.query_projection(q).view(batch_size, q_len,  self.num_heads, self.d_k)\n",
    "        v = self.value_projection(v).view(batch_size, v_len,  self.num_heads, self.d_k)\n",
    "        \n",
    "        attention = scaled_dot_product_attention(\n",
    "            q.transpose(1, 2), \n",
    "            k.transpose(1, 2), \n",
    "            self.d_k, \n",
    "            self.mask\n",
    "        )\n",
    "        output = torch.matmul(attention, v.transpose(1, 2))\n",
    "        output = self.output_layer(output.transpose(1, 2).contiguous().view(batch_size, q_len, -1))\n",
    "\n",
    "        h = self.dropout(output) + residual\n",
    "\n",
    "        h = h.permute(0, 2, 1).view(batch_size, n_channels, height, width)\n",
    "        \n",
    "        return h\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {},
   "outputs": [],
   "source": [
    "example_image = torch.randn(2, 3, 128, 128)\n",
    "conv_block = ConvBlock(3, 32, 2)\n",
    "h_example_image = conv_block(example_image)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([2, 32, 128, 128])"
      ]
     },
     "execution_count": 111,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "attention_block = Attention(d_k=64, dropout=0.1, num_heads=3, num_channels=32, num_groups=8)\n",
    "attn_output = attention_block(h_example_image)\n",
    "attn_output.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Timestep Encoding and Embedding\n",
    "\n",
    "TODO: Explain"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {},
   "outputs": [],
   "source": [
    "def timestep_encoding(curr_t: torch.Tensor, T: torch.Tensor, embedding_dim: int, n=10000, device: torch.device = \"cpu\"):\n",
    "    \"\"\"\n",
    "    Naive sin/cosin positional embedding adapted for timestep embedding in DDPM\n",
    "    \"\"\"\n",
    "    curr_t = curr_t / T # normalize the timestep to be between 0 and 1\n",
    "    p = torch.zeros((curr_t.shape[-1], embedding_dim)).to(device) # initialize the positional embedding tensor\n",
    "\n",
    "    m = torch.arange(int(embedding_dim/2)).to(device) # this is divided by two because we alternate between sin and cos\n",
    "    denominators = torch.pow(n, (2*m/embedding_dim))  # compute the denominators for the sin and cos functions\n",
    "    \n",
    "    p[:, 0::2] = torch.sin(curr_t.unsqueeze(1) / denominators.unsqueeze(0))\n",
    "    p[:, 1::2] = torch.cos(curr_t.unsqueeze(1) / denominators.unsqueeze(0))\n",
    "    return p\n",
    "\n",
    "\n",
    "\n",
    "class TimestepEmbedding(nn.Module):\n",
    "    \"\"\"\n",
    "    Embeds the timestep into a higher dimensional space using a 2 layer MLP.\n",
    "    \"\"\"\n",
    "    def __init__(self,\n",
    "                in_channels: int, \n",
    "                embedding_dim: int, \n",
    "                activation: nn.Module = nn.ReLU\n",
    "                ):\n",
    "        \"\"\"\n",
    "        Args:\n",
    "            in_channels: number of input channels\n",
    "            embedding_dim: dimension of the embedding space\n",
    "            activation: activation function\n",
    "        \"\"\"\n",
    "        super(TimestepEmbedding, self).__init__()\n",
    "        self.linear1 = nn.Linear(in_channels, embedding_dim)\n",
    "        self.linear2 = nn.Linear(embedding_dim, embedding_dim)\n",
    "        self.activation = activation()\n",
    "\n",
    "    def forward(self, curr_t: torch.Tensor, T: torch.Tensor):\n",
    "        x = self.linear1(curr_t)\n",
    "        x = self.activation(x)\n",
    "        x = self.linear2(x)\n",
    "        x = self.activation(x)\n",
    "        \n",
    "        return x"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## UNet Illustrated\n",
    "\n",
    "I found that there weren't too many good illustrations of the specific UNet architecture used in DDPMs, so I decided to make my own. Hopefully this helps someone understand how UNets are implemented for diffusion, or at least understand my specific implementation better. \n",
    "\n",
    "This UNet is built off of the ConvBlocks and the TimestepEmbedding that we defined earlier. \n",
    "\n",
    "# <img src=\"images/ddpm_unet_illustrated.png\" alt=\"UNet Illustrated\" width=\"50%\"/>\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {},
   "outputs": [],
   "source": [
    "class LeftBlock(nn.Module):\n",
    "    \"\"\"\n",
    "    Downampling (left) side of the UNet.\n",
    "    Excludes the bottom-most conv block.\n",
    "    \"\"\"\n",
    "    def __init__(\n",
    "            self, \n",
    "            in_channels: int, \n",
    "            filters: list[int], \n",
    "            num_layers: int, \n",
    "            has_attention: bool = False, \n",
    "            num_heads: int = 8, \n",
    "            dropout: float = 0.2, \n",
    "            timestep_emb_dim: int = None\n",
    "            ):\n",
    "        super(LeftBlock, self).__init__()\n",
    "        \n",
    "        self.has_attention = has_attention\n",
    "        conv_blocks = [ConvBlock(in_channels, filters[0], num_layers, timestep_emb_dim=timestep_emb_dim)]\n",
    "        attention_blocks = [\n",
    "            Attention(\n",
    "                d_k=64, \n",
    "                dropout=0.1, \n",
    "                num_heads=num_heads, \n",
    "                num_channels=filters[0], \n",
    "            )\n",
    "        ] if has_attention else []\n",
    "        \n",
    "        for i in range(1, len(filters)):\n",
    "            conv_blocks.append(ConvBlock(filters[i-1], filters[i], num_layers, timestep_emb_dim=timestep_emb_dim))\n",
    "            if has_attention:\n",
    "                attention_blocks.append(\n",
    "                    Attention(\n",
    "                        d_k=64, \n",
    "                        dropout=0.1, \n",
    "                        num_heads=num_heads, \n",
    "                        num_channels=filters[i], \n",
    "                    )\n",
    "                )\n",
    "        \n",
    "        self.conv_blocks = nn.ModuleList(conv_blocks)\n",
    "        self.attention_blocks = nn.ModuleList(attention_blocks)\n",
    "        \n",
    "        self.maxpool = nn.MaxPool2d(kernel_size=2, stride=2)\n",
    "\n",
    "    def forward(self, x, timestep_emb=None):\n",
    "        residual_outputs = []\n",
    "        for i, conv_block in enumerate(self.conv_blocks):\n",
    "            x = conv_block(x, timestep_emb)\n",
    "            if self.has_attention:\n",
    "                x = self.attention_blocks[i](x)\n",
    "            \n",
    "            residual_outputs.append(x)\n",
    "            x = self.maxpool(x)\n",
    "\n",
    "        return residual_outputs, x\n",
    "\n",
    "\n",
    "class RightBlock(nn.Module):\n",
    "    \"\"\"\n",
    "    Upsampling (right) side of the UNet.\n",
    "    \"\"\"\n",
    "    def __init__(\n",
    "            self, \n",
    "            filters: list[int], \n",
    "            num_layers: int, \n",
    "            has_attention: bool = False, \n",
    "            num_heads: int = 8, \n",
    "            dropout: float = 0.2,\n",
    "            timestep_emb_dim: int = None,\n",
    "            ):\n",
    "        super(RightBlock, self).__init__()\n",
    "        self.has_attention = has_attention\n",
    "\n",
    "        conv_layers = []\n",
    "        upsample_layers = []\n",
    "        attention_layers = []\n",
    "        \n",
    "        for i in range(len(filters) - 2):\n",
    "            conv_layers.append(\n",
    "                ConvBlock(filters[i], filters[i+1], num_layers, timestep_emb_dim=timestep_emb_dim)\n",
    "            )\n",
    "            upsample_layers.append(\n",
    "                nn.ConvTranspose2d(filters[i+1], filters[i+1]//2, 2, stride=2)\n",
    "            )\n",
    "\n",
    "            if has_attention:\n",
    "                attention_layers.append(\n",
    "                    Attention(d_k=64, dropout=0.1, num_heads=num_heads, num_channels=filters[i+1]//2)\n",
    "                )\n",
    "        conv_layers.append(\n",
    "            ConvBlock(filters[-2], filters[-1], num_layers, timestep_emb_dim=timestep_emb_dim)\n",
    "        )\n",
    "\n",
    "        self.conv_layers = nn.ModuleList(conv_layers)\n",
    "        self.attention_layers = nn.ModuleList(attention_layers)\n",
    "        self.upsample_layers = nn.ModuleList(upsample_layers)\n",
    "    \n",
    "    def forward(self, x, residual_outputs, timestep_emb=None):\n",
    "        for i in range(len(self.conv_layers)):\n",
    "            residual = residual_outputs[-(i+1)]\n",
    "            _, _, h, w = x.shape\n",
    "            residual = residual[:, :, :h, :w]\n",
    "\n",
    "            x = torch.cat([x, residual], dim=1)\n",
    "            x = self.conv_layers[i](x, timestep_emb)\n",
    "\n",
    "            if i < len(self.upsample_layers):\n",
    "                x = self.upsample_layers[i](x)\n",
    "\n",
    "                if self.has_attention:\n",
    "                    x = self.attention_layers[i](x)\n",
    "        \n",
    "        return x\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {},
   "outputs": [],
   "source": [
    "db = LeftBlock(in_channels=3, filters=[32, 64, 128], num_layers=2, has_attention=True, num_heads=3, timestep_emb_dim=128)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {},
   "outputs": [],
   "source": [
    "timesteps = torch.randint(0, 1000, (2,))\n",
    "t_encoded = timestep_encoding(timesteps, 1000, 32)\n",
    "t_encoded.shape # N x 32\n",
    "\n",
    "time_embedding_layer = TimestepEmbedding(in_channels=32, embedding_dim=128, activation=nn.ReLU) # N x 32 -> N x 128 (embedding_dim)\n",
    "t_embedded = time_embedding_layer(curr_t=t_encoded, T=1000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([2, 128, 16, 16])"
      ]
     },
     "execution_count": 116,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a = db(torch.randn(2, 3, 128, 128), timestep_emb=t_embedded)\n",
    "a[1].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([2, 32, 128, 128])\n",
      "----------\n",
      "torch.Size([2, 64, 64, 64])\n",
      "----------\n",
      "torch.Size([2, 128, 32, 32])\n",
      "----------\n",
      "torch.Size([2, 128, 16, 16])\n"
     ]
    }
   ],
   "source": [
    "for residual_output in a[0]:\n",
    "    print(residual_output.shape)\n",
    "    print(\"-\"*10)\n",
    "\n",
    "print(a[1].shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([2, 128, 32, 32])"
      ]
     },
     "execution_count": 118,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bottom_conv = nn.Sequential(ResBlock(128, 256), nn.ConvTranspose2d(256, 128, 2, stride=2))\n",
    "bottom_conv(a[1]).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "metadata": {},
   "outputs": [],
   "source": [
    "up = RightBlock(filters=[256, 128, 64, 32], num_layers=2, has_attention=True, num_heads=3, timestep_emb_dim=128)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([2, 128, 32, 32])"
      ]
     },
     "execution_count": 120,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bottom_out = bottom_conv(a[1])\n",
    "bottom_out.shape\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([2, 32, 128, 128])"
      ]
     },
     "execution_count": 121,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "up_out = up(bottom_out, a[0], t_embedded)\n",
    "up_out.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "metadata": {},
   "outputs": [],
   "source": [
    "class UNet(nn.Module):\n",
    "    \"\"\"\n",
    "    UNet model for DDPM.\n",
    "    \"\"\"\n",
    "    def __init__(self,\n",
    "                 down_filters: list[int], \n",
    "                 in_channels: int, \n",
    "                 num_layers: int, \n",
    "                 has_attention: bool = False, \n",
    "                 num_heads: int = 8,\n",
    "                 diffusion_steps: int = None,\n",
    "                 num_groups: int = 8,\n",
    "                 activation: nn.Module = nn.ReLU,\n",
    "                 timestep_emb_dim: int = None\n",
    "                ):\n",
    "        super(UNet, self).__init__()\n",
    "        self.T = diffusion_steps\n",
    "        self.down_filters = down_filters\n",
    "\n",
    "        self.time_embed_dim = down_filters[0] * 4 \n",
    "        \n",
    "        if self.T is not None:\n",
    "            self.timestep_embedding = TimestepEmbedding(\n",
    "                in_channels=self.down_filters[0], \n",
    "                embedding_dim=self.time_embed_dim, \n",
    "                activation=activation, \n",
    "            )\n",
    "        \n",
    "        \n",
    "        self.left_block = LeftBlock(\n",
    "            filters=down_filters, \n",
    "            num_layers=num_layers, \n",
    "            in_channels=in_channels, \n",
    "            has_attention=has_attention, \n",
    "            num_heads=num_heads\n",
    "        )\n",
    "        \n",
    "        # the bottom-most (middle) conv block \n",
    "        if has_attention:\n",
    "            self.middle_conv = ConvBlock(\n",
    "                down_filters[-1], \n",
    "                down_filters[-1]*2, \n",
    "                num_layers, \n",
    "                timestep_emb_dim=timestep_emb_dim\n",
    "            )\n",
    "            self.middle_attention = Attention(d_k=64, dropout=0.1, num_heads=num_heads, num_channels=down_filters[-1]*2)\n",
    "            self.middle_upsample = nn.ConvTranspose2d(down_filters[-1]*2, down_filters[-1], 2, stride=2)\n",
    "        else:\n",
    "            self.middle_conv = ConvBlock(\n",
    "                down_filters[-1], \n",
    "                down_filters[-1]*2, \n",
    "                num_layers, \n",
    "                timestep_emb_dim=timestep_emb_dim\n",
    "            )\n",
    "            self.middle_attention = None\n",
    "            self.middle_upsample = nn.ConvTranspose2d(down_filters[-1]*2, down_filters[-1], 2, stride=2)\n",
    "        \n",
    "        self.up_filters = [down_filters[-1]*2]\n",
    "        self.up_filters.extend(reversed(down_filters))\n",
    "        self.right_block = RightBlock(\n",
    "            filters=self.up_filters, \n",
    "            num_layers=num_layers, \n",
    "            has_attention=has_attention, \n",
    "            num_heads=num_heads,\n",
    "            timestep_emb_dim=timestep_emb_dim\n",
    "        )\n",
    "\n",
    "        self.group_norm = nn.GroupNorm(num_groups=in_channels, num_channels=in_channels)\n",
    "        self.conv_out = nn.Conv2d(in_channels=down_filters[0], out_channels=in_channels, kernel_size=3, padding=1)\n",
    "    \n",
    "    def forward(self, x, t):\n",
    "        if self.T is not None:\n",
    "            t_encoded = timestep_encoding(t, self.T, self.down_filters[0], n = 4000, device=x.device)\n",
    "            t_emb = self.timestep_embedding(curr_t=t_encoded, T=self.T)\n",
    "            t_emb = t_emb.view(-1, self.time_embed_dim, 1, 1)\n",
    "        else: \n",
    "            t_emb = None\n",
    "\n",
    "        x = self.group_norm(x)\n",
    "        residual_outputs, down_output = self.left_block(x, t_emb)\n",
    "        \n",
    "        bottom_output = self.middle_conv(down_output, t_emb)\n",
    "        if self.middle_attention is not None:\n",
    "            bottom_output = self.middle_attention(bottom_output)\n",
    "        \n",
    "        bottom_output = self.middle_upsample(bottom_output)\n",
    "\n",
    "        right_out = self.right_block(bottom_output, residual_outputs, t_emb)\n",
    "        \n",
    "        output = self.conv_out(right_out)\n",
    "        return output\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "metadata": {},
   "outputs": [],
   "source": [
    "u_net = UNet(down_filters=[32, 64, 128], in_channels=3, num_layers=2, has_attention=True, num_heads=3, diffusion_steps=1000)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The UNet model has 4,442,319 trainable parameters.\n"
     ]
    }
   ],
   "source": [
    "def count_parameters(model):\n",
    "    return sum(p.numel() for p in model.parameters() if p.requires_grad)\n",
    "\n",
    "num_params = count_parameters(u_net)\n",
    "print(f\"The UNet model has {num_params:,} trainable parameters.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([16, 3, 32, 32])"
      ]
     },
     "execution_count": 125,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "device = torch.device(\"mps\" if torch.backends.mps.is_available() else \"cpu\")\n",
    "\n",
    "sample_inputs = torch.randn(16, 3, 32, 32).to(device)\n",
    "u_net.to(device)\n",
    "sample_outputs = u_net(sample_inputs, torch.randint(0, 1000, (15,)).to(device))\n",
    "sample_outputs.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training and Validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_alpha_bar(beta_schedule: torch.Tensor):\n",
    "    \"\"\"\n",
    "    what we need to do here is prepare a tensor of alpha_bars where each t'th entry\n",
    "    in alphabars is the product of the alphas leading up to it. Alpha is  as 1 - beta\n",
    "    \"\"\"\n",
    "    alpha = 1. - beta_schedule\n",
    "    return alpha.cumprod(dim=0)\n",
    "\n",
    "def prepare_batch(x: torch.Tensor, T: int, beta_schedule: torch.Tensor):\n",
    "    \"\"\"\n",
    "    Prepare a batch for training by generating random timesteps and adding noise to the image.\n",
    "    We use the random timesteps to generate the amount of noise that should be added to the image at that timestep.\n",
    "    Then, we add the noise to the image.\n",
    "    \n",
    "    Args:\n",
    "        x: the input image\n",
    "        T: the number of diffusion steps\n",
    "        beta_schedule: the beta values for each timestep\n",
    "    \n",
    "    Returns:\n",
    "        the noisy image and the timestep \n",
    "        the noise that was added to the image\n",
    "    \"\"\"\n",
    "    batch_size = x.shape[0]\n",
    "    device = x.device\n",
    "    t = torch.randint(0, T, (batch_size,)).to(device)\n",
    "    e = torch.randn_like(x).to(device)\n",
    "    \n",
    "    alpha_bar_t = get_alpha_bar(beta_schedule)[t]\n",
    "    alpha_bar_t = alpha_bar_t.view(-1, 1, 1, 1)\n",
    "    \n",
    "    noisy_images = alpha_bar_t.sqrt() * x + (1 - alpha_bar_t).sqrt() * e\n",
    "    \n",
    "    return (noisy_images, t), e"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([16, 3, 32, 32])\n",
      "torch.Size([16])\n",
      "torch.Size([16, 3, 32, 32])\n"
     ]
    }
   ],
   "source": [
    "beta_schedule = torch.linspace(0, 1, 1000).to(device)\n",
    "prepare_batch(sample_inputs, 1000, beta_schedule)\n",
    "\n",
    "\n",
    "(noisy_images, t), noise = prepare_batch(sample_inputs, 1000, beta_schedule)\n",
    "\n",
    "# noise and the noisy images should have the same shape\n",
    "# t should be a tensor of shape (batch_size, )\n",
    "print(noisy_images.shape)\n",
    "print(t.shape)\n",
    "print(noise.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "metadata": {},
   "outputs": [],
   "source": [
    "def validate_model(\n",
    "        model, \n",
    "        valid_loader, \n",
    "        loss_fn, \n",
    "        all_valid_loss, \n",
    "        T, \n",
    "        beta_schedule, \n",
    "        using_diffusers: bool = False\n",
    "        ):\n",
    "    model.eval()\n",
    "    valid_loss = []\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        for batch in valid_loader:\n",
    "            x, _ = batch\n",
    "            (noisy_images, t), e = prepare_batch(x, T, beta_schedule)\n",
    "            if using_diffusers:\n",
    "                y_pred = model(noisy_images, t).sample # sample for diffusers library components\n",
    "            else:\n",
    "                y_pred = model(noisy_images, t)\n",
    "            loss = loss_fn(y_pred, e)\n",
    "            valid_loss.append(loss.item())\n",
    "    \n",
    "    all_valid_loss.append(sum(valid_loss) / len(valid_loss))\n",
    "\n",
    "def plot_loss(all_train_loss, all_valid_loss):\n",
    "    plt.figure(figsize=(10, 5))\n",
    "    plt.plot(all_train_loss, label='Training Loss')\n",
    "    plt.plot(all_valid_loss, label='Validation Loss')\n",
    "    plt.xlabel('Epoch')\n",
    "    plt.ylabel('Loss')\n",
    "    plt.legend()\n",
    "    plt.show()\n",
    "\n",
    "\n",
    "def train_model(model: nn.Module,\n",
    "                optim: torch.optim.Optimizer,\n",
    "                loss_fn: nn.Module,\n",
    "                train_loader: torch.utils.data.DataLoader,\n",
    "                valid_loader: torch.utils.data.DataLoader,\n",
    "                scheduler: torch.optim.lr_scheduler._LRScheduler,\n",
    "                beta_schedule: torch.Tensor,\n",
    "                epochs: int = 10,\n",
    "                valid_every: int = 1,\n",
    "                T: int = 1000,\n",
    "                using_diffusers: bool = False\n",
    "                ):\n",
    "\n",
    "    all_train_loss = []\n",
    "    all_valid_loss = []\n",
    "\n",
    "    alpha_bar = get_alpha_bar(beta_schedule)\n",
    "    \n",
    "    for epoch in range(epochs):\n",
    "        print(f\"Epoch {epoch} of {epochs}\")\n",
    "        model.train()\n",
    "        train_loss = []\n",
    "\n",
    "        \n",
    "        for batch in train_loader:\n",
    "            x, _ = batch\n",
    "            (noisy_images, t), e = prepare_batch(x, T, beta_schedule)\n",
    "            optim.zero_grad()\n",
    "            if using_diffusers:\n",
    "                y_pred = model(noisy_images, t).sample # sample for diffusers library components\n",
    "            else:\n",
    "                y_pred = model(noisy_images, t)\n",
    "\n",
    "            loss = loss_fn(y_pred, e)\n",
    "            loss.backward()\n",
    "            optim.step()\n",
    "            train_loss.append(loss.item())\n",
    "        \n",
    "        all_train_loss.append(sum(train_loss) / len(train_loss))\n",
    "        scheduler.step()\n",
    "        \n",
    "        if epoch % valid_every == 0:\n",
    "            validate_model(model, valid_loader, loss_fn, all_valid_loss, T, beta_schedule, using_diffusers)\n",
    "            print(\n",
    "                f\"Epoch {epoch}, Train Loss: {sum(train_loss) / len(train_loss)}, \"\n",
    "                f\"Valid Loss: {all_valid_loss[-1]}\"\n",
    "            )\n",
    "\n",
    "    plot_loss(all_train_loss, all_valid_loss)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_batches_data = []\n",
    "all_batches_labels = []\n",
    "\n",
    "for i in range(1, 6):\n",
    "    with open(f'cifar-10-batches-py/data_batch_{i}', 'rb') as f:\n",
    "        dataset_dict = pickle.load(f, encoding='bytes')\n",
    "        all_batches_data.append(dataset_dict[b'data'])\n",
    "        all_batches_labels.append(dataset_dict[b'labels'])\n",
    "\n",
    "stacked_data = np.vstack(all_batches_data)\n",
    "stacked_labels = np.hstack(all_batches_labels)\n",
    "\n",
    "data = torch.tensor(stacked_data, dtype=torch.float32).view(-1, 3, 32, 32).to(device) / 255.\n",
    "labels = torch.tensor(stacked_labels, dtype=torch.long).to(device)\n",
    "\n",
    "split_idx = int(0.8 * len(data))\n",
    "\n",
    "x_train, x_valid = data[:split_idx], data[split_idx:]\n",
    "y_train, y_valid = labels[:split_idx], labels[split_idx:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train dataset size: 60000\n",
      "Validation dataset size: 10000\n",
      "Number of batches in train_dl: 469\n",
      "Number of batches in valid_dl: 79\n"
     ]
    }
   ],
   "source": [
    "from torch.utils.data import Dataset, DataLoader\n",
    "\n",
    "class CIFARCustomDataset(Dataset):\n",
    "    def __init__(self, x, y):\n",
    "        self.x = x\n",
    "        self.y = y\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.x)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        return self.x[idx], self.y[idx]\n",
    "\n",
    "\n",
    "\n",
    "cifar_train_ds = CIFARCustomDataset(x_train, y_train)\n",
    "cifar_valid_ds = CIFARCustomDataset(x_valid, y_valid)\n",
    "\n",
    "cifar_train_dl = DataLoader(cifar_train_ds, batch_size=128, shuffle=True)\n",
    "cifar_valid_dl = DataLoader(cifar_valid_ds, batch_size=128, shuffle=False)\n",
    "\n",
    "cifar_train_dl = [(x.to(device), y.to(device)) for x, y in cifar_train_dl]\n",
    "cifar_valid_dl = [(x.to(device), y.to(device)) for x, y in cifar_valid_dl]\n",
    "\n",
    "from torchvision import datasets, transforms\n",
    "from torch.utils.data import DataLoader\n",
    "\n",
    "# Define the transform\n",
    "transform = transforms.Compose([\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize((0.1307,), (0.3081,)),\n",
    "    transforms.Pad(2)\n",
    "])\n",
    "\n",
    "# Load MNIST dataset\n",
    "train_dataset = datasets.MNIST(root='./data', train=True, download=True, transform=transform)\n",
    "valid_dataset = datasets.MNIST(root='./data', train=False, download=True, transform=transform)\n",
    "\n",
    "# Create DataLoaders\n",
    "train_dl = DataLoader(train_dataset, batch_size=128, shuffle=True)\n",
    "valid_dl = DataLoader(valid_dataset, batch_size=128, shuffle=False)\n",
    "\n",
    "# Move data to device\n",
    "train_dl = [(x.to(device), y.to(device)) for x, y in train_dl]\n",
    "valid_dl = [(x.to(device), y.to(device)) for x, y in valid_dl]\n",
    "\n",
    "print(f\"Train dataset size: {len(train_dataset)}\")\n",
    "print(f\"Validation dataset size: {len(valid_dataset)}\")\n",
    "print(f\"Number of batches in train_dl: {len(train_dl)}\")\n",
    "print(f\"Number of batches in valid_dl: {len(valid_dl)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The UNet model has 2,185,861 trainable parameters.\n",
      "Epoch 0 of 10\n",
      "Epoch 0, Train Loss: 0.37646556961765165, Valid Loss: 0.13688158121290087\n",
      "Epoch 1 of 10\n",
      "Epoch 1, Train Loss: 0.17911756216590083, Valid Loss: 0.10647825745842125\n",
      "Epoch 2 of 10\n",
      "Epoch 2, Train Loss: 0.14282998769903488, Valid Loss: 0.10811741763277899\n",
      "Epoch 3 of 10\n",
      "Epoch 3, Train Loss: 0.12548003240879665, Valid Loss: 0.14910377052765858\n",
      "Epoch 4 of 10\n",
      "Epoch 4, Train Loss: 0.11455197803882648, Valid Loss: 0.21072515920747684\n",
      "Epoch 5 of 10\n",
      "Epoch 5, Train Loss: 0.10774701519180209, Valid Loss: 0.2543925882517537\n",
      "Epoch 6 of 10\n",
      "Epoch 6, Train Loss: 0.10291269122918786, Valid Loss: 0.31008865335319613\n",
      "Epoch 7 of 10\n",
      "Epoch 7, Train Loss: 0.09877409102883675, Valid Loss: 0.3108392836926859\n",
      "Epoch 8 of 10\n",
      "Epoch 8, Train Loss: 0.09590190132734364, Valid Loss: 0.339351252287249\n",
      "Epoch 9 of 10\n",
      "Epoch 9, Train Loss: 0.0935514317805579, Valid Loss: 0.35356946723370614\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 1000x500 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "model = UNet(\n",
    "    down_filters=[32, 64, 128], \n",
    "    in_channels=1, \n",
    "    num_layers=1, \n",
    "    has_attention=True, \n",
    "    num_heads=1, \n",
    "    diffusion_steps=1000,\n",
    ").to(device)\n",
    "\n",
    "num_params = count_parameters(model)\n",
    "print(f\"The UNet model has {num_params:,} trainable parameters.\")\n",
    "\n",
    "optim = torch.optim.Adam(model.parameters(), lr=3e-4)\n",
    "scheduler = torch.optim.lr_scheduler.OneCycleLR(optim, max_lr=1e-3, steps_per_epoch=len(train_dl), epochs=10)\n",
    "loss_fn = nn.MSELoss()\n",
    "\n",
    "beta_schedule = torch.linspace(0.0001, 0.02, 1000).to(device)\n",
    "\n",
    "train_model(\n",
    "    model=model, \n",
    "    optim=optim, \n",
    "    loss_fn=loss_fn, \n",
    "    train_loader=train_dl, \n",
    "    valid_loader=valid_dl, \n",
    "    scheduler=scheduler, \n",
    "    beta_schedule=beta_schedule, \n",
    "    epochs=10, \n",
    "    valid_every=1,\n",
    "    T=1000\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "metadata": {},
   "outputs": [],
   "source": [
    "def sample_images(model, beta_schedule, T, device, num_samples=16, using_diffusers: bool = False):\n",
    "    model.eval()\n",
    "    with torch.no_grad():\n",
    "        x = torch.randn(num_samples, 1, 32, 32).to(device)\n",
    "        for t in reversed(range(T)):\n",
    "            time_input = torch.full((16,), t, device=device)\n",
    "            beta_t = beta_schedule[t]\n",
    "            alpha_t = 1. - beta_t\n",
    "            sigma_t = beta_t.sqrt()\n",
    "            \n",
    "            alpha_bar_t = alpha_bar(beta_t)\n",
    "            z = torch.randn_like(x).to(device) if t > 0 else 0\n",
    "            if using_diffusers:\n",
    "                model_pred = model(x, time_input).sample\n",
    "            else:\n",
    "                model_pred = model(x, time_input)\n",
    "            x_t_minus_1 = (1 / alpha_t.sqrt()) * (x - (1 - alpha_bar_t) / (1 - alpha_bar_t).sqrt() * model_pred) + sigma_t * z\n",
    "            x = x_t_minus_1\n",
    "\n",
    "    return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from src.utils import show_torch_image\n",
    "sampled_images = sample_images(model, beta_schedule, 1000, device, num_samples=16)\n",
    "sampled_images_cpu = sampled_images.cpu()\n",
    "for i in range(16):\n",
    "    show_torch_image(sampled_images_cpu[i])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/apandya/computer_vision/.venv/lib/python3.10/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "from diffusers import UNet2DModel\n",
    "\n",
    "model = UNet2DModel(in_channels=1, out_channels=1, block_out_channels=(32, 64, 128, 128)).to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0 of 10\n",
      "Epoch 0, Train Loss: 1.1015475007262565, Valid Loss: 1.1024473090715046\n",
      "Epoch 1 of 10\n",
      "Epoch 1, Train Loss: 1.1011762331797879, Valid Loss: 1.1013112309612805\n",
      "Epoch 2 of 10\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[136], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[43mtrain_model\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m      2\u001b[0m \u001b[43m    \u001b[49m\u001b[43mmodel\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\n\u001b[1;32m      3\u001b[0m \u001b[43m    \u001b[49m\u001b[43moptim\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43moptim\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\n\u001b[1;32m      4\u001b[0m \u001b[43m    \u001b[49m\u001b[43mloss_fn\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mloss_fn\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\n\u001b[1;32m      5\u001b[0m \u001b[43m    \u001b[49m\u001b[43mtrain_loader\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtrain_dl\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\n\u001b[1;32m      6\u001b[0m \u001b[43m    \u001b[49m\u001b[43mvalid_loader\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mvalid_dl\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\n\u001b[1;32m      7\u001b[0m \u001b[43m    \u001b[49m\u001b[43mscheduler\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mscheduler\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\n\u001b[1;32m      8\u001b[0m \u001b[43m    \u001b[49m\u001b[43mbeta_schedule\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mbeta_schedule\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\n\u001b[1;32m      9\u001b[0m \u001b[43m    \u001b[49m\u001b[43mepochs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m10\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\n\u001b[1;32m     10\u001b[0m \u001b[43m    \u001b[49m\u001b[43mvalid_every\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m     11\u001b[0m \u001b[43m    \u001b[49m\u001b[43mT\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m1000\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m     12\u001b[0m \u001b[43m    \u001b[49m\u001b[43musing_diffusers\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\n\u001b[1;32m     13\u001b[0m \u001b[43m)\u001b[49m\n",
      "Cell \u001b[0;32mIn[128], line 69\u001b[0m, in \u001b[0;36mtrain_model\u001b[0;34m(model, optim, loss_fn, train_loader, valid_loader, scheduler, beta_schedule, epochs, valid_every, T, using_diffusers)\u001b[0m\n\u001b[1;32m     67\u001b[0m     loss\u001b[38;5;241m.\u001b[39mbackward()\n\u001b[1;32m     68\u001b[0m     optim\u001b[38;5;241m.\u001b[39mstep()\n\u001b[0;32m---> 69\u001b[0m     train_loss\u001b[38;5;241m.\u001b[39mappend(\u001b[43mloss\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mitem\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m)\n\u001b[1;32m     71\u001b[0m all_train_loss\u001b[38;5;241m.\u001b[39mappend(\u001b[38;5;28msum\u001b[39m(train_loss) \u001b[38;5;241m/\u001b[39m \u001b[38;5;28mlen\u001b[39m(train_loss))\n\u001b[1;32m     72\u001b[0m scheduler\u001b[38;5;241m.\u001b[39mstep()\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "train_model(\n",
    "    model=model, \n",
    "    optim=optim, \n",
    "    loss_fn=loss_fn, \n",
    "    train_loader=train_dl, \n",
    "    valid_loader=valid_dl, \n",
    "    scheduler=scheduler, \n",
    "    beta_schedule=beta_schedule, \n",
    "    epochs=10, \n",
    "    valid_every=1,\n",
    "    T=1000,\n",
    "    using_diffusers=True\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sampled_images = sample_images(model, beta_schedule, 1000, device, num_samples=16, using_diffusers=True)\n",
    "sampled_images_cpu = sampled_images.cpu()\n",
    "for i in range(16):\n",
    "    show_torch_image(sampled_images_cpu[i])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "fastai",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.15"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

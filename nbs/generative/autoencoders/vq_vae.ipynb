{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Vector Quantized Variational Autoencoders (VQ-VAEs)\n",
    "\n",
    "Rather than computing a continuous latent representation of the input, in VQ-VAEs we compute a discrete latent representation. Here, our encoder output is discretized with respect to a learned discrete set of embeddings we refer to as a codebook.\n",
    "\n",
    "The goal here is to tackle the smoothing problem noticed in general VAEs, as well as to reduce computational complexity. We can then use the (encoder + codebook) as a tokenizer for different types of transformers."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 251,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "\n",
    "from torch.utils.data import Dataset, DataLoader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 252,
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device(\"mps\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 253,
   "metadata": {},
   "outputs": [],
   "source": [
    "class VQVAE(nn.Module):\n",
    "    def __init__(\n",
    "        self,\n",
    "        input_dim: int,\n",
    "        n_channels: int,\n",
    "        latent_dim: int,\n",
    "        codebook_size: int,\n",
    "    ):\n",
    "        super().__init__()\n",
    "        \n",
    "        self.latent_dim = latent_dim\n",
    "        \n",
    "        self.encoder = nn.Sequential(\n",
    "            nn.Conv2d(n_channels, 96, kernel_size=3, stride=2, padding=1),\n",
    "            nn.ReLU(),\n",
    "            nn.BatchNorm2d(96),\n",
    "            nn.Conv2d(96, 192, kernel_size=3, stride=2, padding=1),\n",
    "            nn.ReLU(),\n",
    "            nn.BatchNorm2d(192),\n",
    "            nn.Conv2d(192, 384, kernel_size=3, stride=2, padding=1), \n",
    "            nn.ReLU(),\n",
    "            nn.BatchNorm2d(384),\n",
    "            nn.Conv2d(384, latent_dim, kernel_size=1),\n",
    "            nn.ReLU(),\n",
    "            nn.BatchNorm2d(latent_dim)\n",
    "        )\n",
    "\n",
    "        self.codebook = nn.Parameter(\n",
    "            torch.randn(codebook_size, latent_dim) * 0.02, \n",
    "            requires_grad=True\n",
    "        )\n",
    "        \n",
    "        self.decoder = nn.Sequential(\n",
    "            nn.ConvTranspose2d(latent_dim, 384, kernel_size=1),\n",
    "            nn.ReLU(),\n",
    "            nn.BatchNorm2d(384),\n",
    "            nn.ConvTranspose2d(384, 192, kernel_size=3, stride=2, padding=1, output_padding=1),\n",
    "            nn.ReLU(),\n",
    "            nn.BatchNorm2d(192),\n",
    "            nn.ConvTranspose2d(192, 96, kernel_size=3, stride=2, padding=1, output_padding=1),\n",
    "            nn.ReLU(),\n",
    "            nn.BatchNorm2d(96),\n",
    "            nn.ConvTranspose2d(96, n_channels, kernel_size=3, stride=2, padding=1, output_padding=1),\n",
    "            nn.Sigmoid(),\n",
    "        )\n",
    "        \n",
    "    def forward(self, x: torch.Tensor) -> torch.Tensor:\n",
    "        \"\"\"\n",
    "        Forward pass through the VAE.\n",
    "\n",
    "        Args:\n",
    "            x: input data\n",
    "\n",
    "        Returns:\n",
    "            x_hat: reconstructed data\n",
    "        \"\"\"\n",
    "        z_encoder = self.encoder(x)\n",
    "        z_quantized = self._quantize_encoder_output(z_encoder)\n",
    "        z_q_st = z_encoder + (z_quantized - z_encoder).detach()\n",
    "        return self.decoder(z_q_st), z_encoder, z_quantized\n",
    "    \n",
    "    def _quantize_encoder_output(self, z_e: torch.Tensor) -> torch.Tensor:\n",
    "        \"\"\"\n",
    "        Quantizing the encoded tensor by snapping its elements to the closest codebook \n",
    "        entry.\n",
    "\n",
    "        Args:\n",
    "            z_e: encoded representation\n",
    "\n",
    "        Returns:\n",
    "            z_q: quantized representation\n",
    "        \"\"\"\n",
    "        batch_size, latent_dim, h, w = z_e.shape\n",
    "        encoded = z_e.permute(0, 2, 3, 1).reshape(batch_size*h*w, latent_dim)\n",
    "        quantized = self.codebook[torch.argmin(torch.cdist(encoded, self.codebook), dim=1)]\n",
    "        z_q = quantized.reshape(batch_size, h, w, latent_dim).permute(0, 3, 1, 2)\n",
    "        return z_q"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 254,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Input shape: torch.Size([2, 3, 64, 64])\n",
      "Running forward pass...\n",
      "Output shape: torch.Size([2, 3, 64, 64])\n",
      "z_e.shape: torch.Size([2, 128, 8, 8]), z_quantized.shape: torch.Size([2, 128, 8, 8])\n"
     ]
    }
   ],
   "source": [
    "# Create dummy tensors and model for testing\n",
    "batch_size = 2\n",
    "n_channels = 3\n",
    "height = 64\n",
    "width = 64\n",
    "latent_dim = 128\n",
    "codebook_size = 256\n",
    "\n",
    "dummy_input = torch.randn(batch_size, n_channels, height, width)\n",
    "\n",
    "dummy_model = VQVAE(\n",
    "    input_dim=(n_channels, height, width),\n",
    "    latent_dim=latent_dim,\n",
    "    n_channels=n_channels,\n",
    "    codebook_size=codebook_size\n",
    ")\n",
    "\n",
    "print(\"Input shape:\", dummy_input.shape)\n",
    "print(\"Running forward pass...\")\n",
    "x_hat, z_e, z_quantized = dummy_model(dummy_input)\n",
    "print(f\"Output shape: {x_hat.shape}\")\n",
    "print(f\"z_e.shape: {z_e.shape}, z_quantized.shape: {z_quantized.shape}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Objective Function\n",
    "\n",
    "Our objective function consists of 3 terms:\n",
    "\n",
    "![VQ-VAE Loss Function](images/vq_vae_loss.png)\n",
    "\n",
    "1. Reconstruction Loss: Ensures the decoded output matches the input\n",
    "2. Codebook Loss: Keeps the codebook entries close to the encoded representations  \n",
    "3. Commitment Loss: Prevents the encoder from growing too large\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 255,
   "metadata": {},
   "outputs": [],
   "source": [
    "def validate(\n",
    "    model: nn.Module,\n",
    "    recon_loss_fn: nn.Module,\n",
    "    cb_loss_fn: nn.Module,\n",
    "    commit_loss_fn: nn.Module,\n",
    "    valid_dl: DataLoader,\n",
    "    beta: float = 1.\n",
    "):\n",
    "    model.eval()\n",
    "    with torch.no_grad():\n",
    "        tot_loss = 0.\n",
    "        tot_recon_loss = 0.\n",
    "        tot_codebook_loss = 0.\n",
    "        tot_commit_loss = 0.\n",
    "        num_batches = 0\n",
    "        for xb, _ in valid_dl:\n",
    "            x_hat, z_e, z_quantized = model(xb)\n",
    "            recon_loss = recon_loss_fn(x_hat, xb)\n",
    "            codebook_loss = cb_loss_fn(z_quantized, z_e.detach())\n",
    "            commit_loss = commit_loss_fn(z_e, z_quantized.detach())\n",
    "            loss = recon_loss + codebook_loss + (beta * commit_loss)\n",
    "            \n",
    "            tot_loss += loss.item()\n",
    "            tot_recon_loss += recon_loss.item()\n",
    "            tot_codebook_loss += codebook_loss.item()\n",
    "            tot_commit_loss += commit_loss.item()\n",
    "            num_batches += 1\n",
    "    \n",
    "    tot_loss /= num_batches\n",
    "    tot_recon_loss /= num_batches\n",
    "    tot_codebook_loss /= num_batches\n",
    "    tot_commit_loss /= num_batches\n",
    "\n",
    "    return tot_loss, tot_recon_loss, tot_codebook_loss, tot_commit_loss\n",
    "\n",
    "def kl_loss_func(mu, logvar):\n",
    "    # Clamp logvar for numerical stability\n",
    "    logvar = torch.clamp(logvar, -10, 10)\n",
    "    \n",
    "    kl_loss = -0.5 * torch.sum(1 + logvar - mu.pow(2) - logvar.exp())\n",
    "    return kl_loss / (mu.size(0) * mu.size(1)) # normalize to prevent explosion\n",
    "\n",
    "def fit(\n",
    "    epochs: int, \n",
    "    model: nn.Module,\n",
    "    recon_loss_fn: nn.Module,\n",
    "    cb_loss_fn: nn.Module,\n",
    "    commit_loss_fn: nn.Module,\n",
    "    opt: torch.optim.Optimizer, \n",
    "    train_dl: DataLoader, \n",
    "    valid_dl: DataLoader,\n",
    "    beta: float = 1,\n",
    "    grad_clip: float = 1.0\n",
    "):\n",
    "    for epoch in range(epochs):\n",
    "        print(f\"Epoch {epoch+1}/{epochs}\")\n",
    "        model.train()\n",
    "        for xb, _ in train_dl:\n",
    "            xb = xb.to(device)\n",
    "            x_hat, z_e, z_quantized = model(xb)\n",
    "            recon_loss = recon_loss_fn(x_hat, xb)\n",
    "            codebook_loss = cb_loss_fn(z_quantized, z_e.detach())\n",
    "            commit_loss = commit_loss_fn(z_e, z_quantized.detach())\n",
    "            loss = recon_loss + codebook_loss + (beta * commit_loss)\n",
    "            \n",
    "            opt.zero_grad()\n",
    "            loss.backward()\n",
    "            torch.nn.utils.clip_grad_norm_(model.parameters(), grad_clip)\n",
    "            opt.step()\n",
    "\n",
    "\n",
    "        total_loss, recon_loss, codebook_loss, commit_loss = validate(\n",
    "            model, recon_loss_fn, cb_loss_fn, commit_loss_fn, valid_dl, beta\n",
    "        )\n",
    "        print(f\"Validation loss: {total_loss:.6f}\")\n",
    "        print(f\"Reconstruction loss: {recon_loss:.6f}\")\n",
    "        print(f\"Codebook loss: {codebook_loss:.6f}\")\n",
    "        print(f\"Commit loss: {commit_loss:.6f}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 256,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "import numpy as np\n",
    "import torch\n",
    "\n",
    "\n",
    "all_batches_data = []\n",
    "all_batches_labels = []\n",
    "\n",
    "for i in range(1, 6):\n",
    "    with open(f'data/cifar-10-batches-py/data_batch_{i}', 'rb') as f:\n",
    "        dataset_dict = pickle.load(f, encoding='bytes')\n",
    "        all_batches_data.append(dataset_dict[b'data'])\n",
    "        all_batches_labels.append(dataset_dict[b'labels'])\n",
    "\n",
    "stacked_data = np.vstack(all_batches_data)\n",
    "stacked_labels = np.hstack(all_batches_labels)\n",
    "data = torch.tensor(stacked_data, dtype=torch.float32).view(-1, 3, 32, 32).to(device) / 255.\n",
    "labels = torch.tensor(stacked_labels, dtype=torch.long).to(device)\n",
    "\n",
    "split_idx = int(0.8 * len(data))\n",
    "\n",
    "x_train, x_valid = data[:split_idx], data[split_idx:]\n",
    "y_train, y_valid = labels[:split_idx], labels[split_idx:]\n",
    "\n",
    "class CIFARCustomDataset(Dataset):\n",
    "    def __init__(self, x, y):\n",
    "        self.x = x\n",
    "        self.y = y\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.x)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        return self.x[idx], self.y[idx]\n",
    "\n",
    "train_ds = CIFARCustomDataset(x_train, y_train)\n",
    "valid_ds = CIFARCustomDataset(x_valid, y_valid)\n",
    "\n",
    "train_dl = DataLoader(train_ds, batch_size=64, shuffle=True)\n",
    "valid_dl = DataLoader(valid_ds, batch_size=64, shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 257,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n",
      "Validation loss: 1.108013\n",
      "Reconstruction loss: 0.018216\n",
      "Codebook loss: 0.871838\n",
      "Commit loss: 0.871838\n",
      "Epoch 2/50\n",
      "Validation loss: 0.922930\n",
      "Reconstruction loss: 0.018040\n",
      "Codebook loss: 0.723912\n",
      "Commit loss: 0.723912\n",
      "Epoch 3/50\n",
      "Validation loss: 0.716467\n",
      "Reconstruction loss: 0.017776\n",
      "Codebook loss: 0.558953\n",
      "Commit loss: 0.558953\n",
      "Epoch 4/50\n",
      "Validation loss: 0.532584\n",
      "Reconstruction loss: 0.017864\n",
      "Codebook loss: 0.411776\n",
      "Commit loss: 0.411776\n",
      "Epoch 5/50\n",
      "Validation loss: 0.408299\n",
      "Reconstruction loss: 0.018277\n",
      "Codebook loss: 0.312017\n",
      "Commit loss: 0.312017\n",
      "Epoch 6/50\n",
      "Validation loss: 0.285233\n",
      "Reconstruction loss: 0.018623\n",
      "Codebook loss: 0.213288\n",
      "Commit loss: 0.213288\n",
      "Epoch 7/50\n",
      "Validation loss: 0.211937\n",
      "Reconstruction loss: 0.019152\n",
      "Codebook loss: 0.154228\n",
      "Commit loss: 0.154228\n",
      "Epoch 8/50\n",
      "Validation loss: 0.149656\n",
      "Reconstruction loss: 0.019711\n",
      "Codebook loss: 0.103956\n",
      "Commit loss: 0.103956\n",
      "Epoch 9/50\n",
      "Validation loss: 0.110162\n",
      "Reconstruction loss: 0.019868\n",
      "Codebook loss: 0.072235\n",
      "Commit loss: 0.072235\n",
      "Epoch 10/50\n",
      "Validation loss: 0.085310\n",
      "Reconstruction loss: 0.020062\n",
      "Codebook loss: 0.052198\n",
      "Commit loss: 0.052198\n",
      "Epoch 11/50\n",
      "Validation loss: 0.072577\n",
      "Reconstruction loss: 0.019529\n",
      "Codebook loss: 0.042438\n",
      "Commit loss: 0.042438\n",
      "Epoch 12/50\n",
      "Validation loss: 0.064767\n",
      "Reconstruction loss: 0.019366\n",
      "Codebook loss: 0.036321\n",
      "Commit loss: 0.036321\n",
      "Epoch 13/50\n",
      "Validation loss: 0.059684\n",
      "Reconstruction loss: 0.018946\n",
      "Codebook loss: 0.032590\n",
      "Commit loss: 0.032590\n",
      "Epoch 14/50\n",
      "Validation loss: 0.054044\n",
      "Reconstruction loss: 0.018634\n",
      "Codebook loss: 0.028328\n",
      "Commit loss: 0.028328\n",
      "Epoch 15/50\n",
      "Validation loss: 0.052348\n",
      "Reconstruction loss: 0.018188\n",
      "Codebook loss: 0.027328\n",
      "Commit loss: 0.027328\n",
      "Epoch 16/50\n",
      "Validation loss: 0.050120\n",
      "Reconstruction loss: 0.017658\n",
      "Codebook loss: 0.025969\n",
      "Commit loss: 0.025969\n",
      "Epoch 17/50\n",
      "Validation loss: 0.048939\n",
      "Reconstruction loss: 0.017170\n",
      "Codebook loss: 0.025415\n",
      "Commit loss: 0.025415\n",
      "Epoch 18/50\n",
      "Validation loss: 0.047007\n",
      "Reconstruction loss: 0.016970\n",
      "Codebook loss: 0.024030\n",
      "Commit loss: 0.024030\n",
      "Epoch 19/50\n",
      "Validation loss: 0.045897\n",
      "Reconstruction loss: 0.016659\n",
      "Codebook loss: 0.023390\n",
      "Commit loss: 0.023390\n",
      "Epoch 20/50\n",
      "Validation loss: 0.045581\n",
      "Reconstruction loss: 0.016379\n",
      "Codebook loss: 0.023361\n",
      "Commit loss: 0.023361\n",
      "Epoch 21/50\n",
      "Validation loss: 0.045155\n",
      "Reconstruction loss: 0.016216\n",
      "Codebook loss: 0.023151\n",
      "Commit loss: 0.023151\n",
      "Epoch 22/50\n",
      "Validation loss: 0.044107\n",
      "Reconstruction loss: 0.015988\n",
      "Codebook loss: 0.022495\n",
      "Commit loss: 0.022495\n",
      "Epoch 23/50\n",
      "Validation loss: 0.042632\n",
      "Reconstruction loss: 0.015829\n",
      "Codebook loss: 0.021443\n",
      "Commit loss: 0.021443\n",
      "Epoch 24/50\n",
      "Validation loss: 0.041405\n",
      "Reconstruction loss: 0.015941\n",
      "Codebook loss: 0.020371\n",
      "Commit loss: 0.020371\n",
      "Epoch 25/50\n",
      "Validation loss: 0.043098\n",
      "Reconstruction loss: 0.015722\n",
      "Codebook loss: 0.021901\n",
      "Commit loss: 0.021901\n",
      "Epoch 26/50\n",
      "Validation loss: 0.043129\n",
      "Reconstruction loss: 0.015587\n",
      "Codebook loss: 0.022034\n",
      "Commit loss: 0.022034\n",
      "Epoch 27/50\n",
      "Validation loss: 0.043109\n",
      "Reconstruction loss: 0.015401\n",
      "Codebook loss: 0.022167\n",
      "Commit loss: 0.022167\n",
      "Epoch 28/50\n",
      "Validation loss: 0.043160\n",
      "Reconstruction loss: 0.015351\n",
      "Codebook loss: 0.022247\n",
      "Commit loss: 0.022247\n",
      "Epoch 29/50\n",
      "Validation loss: 0.043126\n",
      "Reconstruction loss: 0.015198\n",
      "Codebook loss: 0.022342\n",
      "Commit loss: 0.022342\n",
      "Epoch 30/50\n",
      "Validation loss: 0.042086\n",
      "Reconstruction loss: 0.015090\n",
      "Codebook loss: 0.021597\n",
      "Commit loss: 0.021597\n",
      "Epoch 31/50\n",
      "Validation loss: 0.042266\n",
      "Reconstruction loss: 0.015068\n",
      "Codebook loss: 0.021759\n",
      "Commit loss: 0.021759\n",
      "Epoch 32/50\n",
      "Validation loss: 0.041513\n",
      "Reconstruction loss: 0.015000\n",
      "Codebook loss: 0.021210\n",
      "Commit loss: 0.021210\n",
      "Epoch 33/50\n",
      "Validation loss: 0.041834\n",
      "Reconstruction loss: 0.014931\n",
      "Codebook loss: 0.021522\n",
      "Commit loss: 0.021522\n",
      "Epoch 34/50\n",
      "Validation loss: 0.040939\n",
      "Reconstruction loss: 0.014897\n",
      "Codebook loss: 0.020834\n",
      "Commit loss: 0.020834\n",
      "Epoch 35/50\n",
      "Validation loss: 0.041330\n",
      "Reconstruction loss: 0.014887\n",
      "Codebook loss: 0.021154\n",
      "Commit loss: 0.021154\n",
      "Epoch 36/50\n",
      "Validation loss: 0.041013\n",
      "Reconstruction loss: 0.014814\n",
      "Codebook loss: 0.020959\n",
      "Commit loss: 0.020959\n",
      "Epoch 37/50\n",
      "Validation loss: 0.041740\n",
      "Reconstruction loss: 0.014787\n",
      "Codebook loss: 0.021563\n",
      "Commit loss: 0.021563\n",
      "Epoch 38/50\n",
      "Validation loss: 0.041089\n",
      "Reconstruction loss: 0.014752\n",
      "Codebook loss: 0.021070\n",
      "Commit loss: 0.021070\n",
      "Epoch 39/50\n",
      "Validation loss: 0.040656\n",
      "Reconstruction loss: 0.014734\n",
      "Codebook loss: 0.020738\n",
      "Commit loss: 0.020738\n",
      "Epoch 40/50\n",
      "Validation loss: 0.041156\n",
      "Reconstruction loss: 0.014755\n",
      "Codebook loss: 0.021120\n",
      "Commit loss: 0.021120\n",
      "Epoch 41/50\n",
      "Validation loss: 0.041007\n",
      "Reconstruction loss: 0.014671\n",
      "Codebook loss: 0.021069\n",
      "Commit loss: 0.021069\n",
      "Epoch 42/50\n",
      "Validation loss: 0.039752\n",
      "Reconstruction loss: 0.014678\n",
      "Codebook loss: 0.020059\n",
      "Commit loss: 0.020059\n",
      "Epoch 43/50\n",
      "Validation loss: 0.040284\n",
      "Reconstruction loss: 0.014656\n",
      "Codebook loss: 0.020503\n",
      "Commit loss: 0.020503\n",
      "Epoch 44/50\n",
      "Validation loss: 0.039680\n",
      "Reconstruction loss: 0.014646\n",
      "Codebook loss: 0.020027\n",
      "Commit loss: 0.020027\n",
      "Epoch 45/50\n",
      "Validation loss: 0.039901\n",
      "Reconstruction loss: 0.014632\n",
      "Codebook loss: 0.020215\n",
      "Commit loss: 0.020215\n",
      "Epoch 46/50\n",
      "Validation loss: 0.039479\n",
      "Reconstruction loss: 0.014596\n",
      "Codebook loss: 0.019907\n",
      "Commit loss: 0.019907\n",
      "Epoch 47/50\n",
      "Validation loss: 0.039592\n",
      "Reconstruction loss: 0.014600\n",
      "Codebook loss: 0.019994\n",
      "Commit loss: 0.019994\n",
      "Epoch 48/50\n",
      "Validation loss: 0.039490\n",
      "Reconstruction loss: 0.014540\n",
      "Codebook loss: 0.019960\n",
      "Commit loss: 0.019960\n",
      "Epoch 49/50\n",
      "Validation loss: 0.040768\n",
      "Reconstruction loss: 0.014577\n",
      "Codebook loss: 0.020952\n",
      "Commit loss: 0.020952\n",
      "Epoch 50/50\n",
      "Validation loss: 0.040377\n",
      "Reconstruction loss: 0.014527\n",
      "Codebook loss: 0.020680\n",
      "Commit loss: 0.020680\n"
     ]
    }
   ],
   "source": [
    "model = VQVAE(\n",
    "    input_dim=(3, 32, 32),\n",
    "    n_channels=3,\n",
    "    latent_dim=128,\n",
    "    codebook_size=256,\n",
    ")\n",
    "\n",
    "recon_loss_fn = nn.MSELoss()\n",
    "cb_loss_fn = nn.MSELoss()\n",
    "commit_loss_fn = nn.MSELoss()\n",
    "opt = torch.optim.AdamW(model.parameters(), lr=1e-4, weight_decay=1e-5)\n",
    "\n",
    "model.to(device)\n",
    "\n",
    "fit(50, model, recon_loss_fn, cb_loss_fn, commit_loss_fn, opt, train_dl, valid_dl, beta=0.25)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 258,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([1, 3, 32, 32])\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAYUAAAGFCAYAAAASI+9IAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjkuMiwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy8hTgPZAAAACXBIWXMAAA9hAAAPYQGoP6dpAAAZcElEQVR4nO3cy44kB3rd8S/ynpWVWbeuS9/IJtnTNDUYciSNhAEtQxpoI28Ee+WH0GP4JbyyXsAwBMEwYMCGBQEeLTQDCpZIjSne+1pd1VVZlffMiAwtDHxe6hyAgD3G/7f++uvIiMg6GYs4RV3XdQAAEBGN/9sHAAD4fwehAABIhAIAIBEKAIBEKAAAEqEAAEiEAgAgEQoAgNRSB3/v9//AWjweX8mz3cbW2n3Y0d+3e+tox9p9fDiQZ+/s71q7O822PNvq9q3d0ZQvZUREXF2P5dl16b3feLC/J882qo21e7VaybPL5dLa3ev3rPkqKnl2vphau/f2R/pwrR9HRMR6tZZnm6HfsxERzWZTnh3uet+fwUD/bkZEtNv69VwY5yQioi6M39MN77vpXJ+yLqzdf/Jv/90/OcOTAgAgEQoAgEQoAAASoQAASIQCACARCgCARCgAABKhAABIhAIAIBEKAIBEKAAAklzK8elnn1qLx5eX8uyhVzkTxZH+D+5UQ293/0SenW31fqeIiGmldwjVRcfaPV963S3zhd4htKm8bqrLpt7H0mt5vUplqR9L0+yc6Xa71vx8OZNny613fYrlkTzb0OuGIiJiY/RH9Vvel3Nq9PZcVaW1e2fH6z4qGnpvU2H0kkVEREP/PT1fev1e5Uafb7a8e1bBkwIAIBEKAIBEKAAAEqEAAEiEAgAgEQoAgEQoAAASoQAASIQCACARCgCAJPcA9Ft6dUFERBhvX79t1FZERDw63ZNnT44Prd1941X6ovDOyWK1lGeXG72KICKiNo+l0+/rw6VXRVFv9WPfO9yxdpcb/Vg6beMzRkRVWePR7Og3+WqtX/uIiE2pX88d4zgiIloD/bz0zN1loVd/NGqvPqUM7x432lZid+Ddh9PZXJ7dlF7NRcM47sntjbVb+v+/940AgF9bhAIAIBEKAIBEKAAAEqEAAEiEAgAgEQoAgEQoAAASoQAASIQCACARCgCAJHcf9YrSWjwcyqvjyf0Da/dRvynPtrde58z0ai3PVlsvUxdz/Rw2OtbqGO3vWvMto9NmfDPxduuXPg6HXufM5Fbv1lkv9dmIiMXS66ipjS6e3YHeqRURsVkv5NlGZZzwiGh39WtfVd45aRmFQ6uVt7vT9r4Uja3+fVtNr63dUekdXF39z1VERJRbvRPqZuZ1pCl4UgAAJEIBAJAIBQBAIhQAAIlQAAAkQgEAkAgFAEAiFAAAiVAAACRCAQCQ5PfjD7req/R941X6vUHf2n08asuz1baydjvTzZb5/npDz+DV1qwXcLolIqJV66/SVyu9ciEiom7qn/P167G1u9roV2gyn1u755VecRIRsdsf6cMr7z5shn59GoVeuRAR0ez25NnFzKuJ2Wnr56RVe8e9XHrXZ7HRay624R3LeKqfl/Hc+y5PjTqc5eb7/13PkwIAIBEKAIBEKAAAEqEAAEiEAgAgEQoAgEQoAAASoQAASIQCACARCgCARCgAAJJcmHO8r/elREQM23ovUK/ndQg1mnpPSb/v9SptSr2jZhuFtbuu9e6Wdel1sVRrr19lW+vztdkJVLc68uxkPbN2V5V+r8wrvT8oIqI05ycz/Rw+v/I+Z7uhH8to6t2Hm1eX8uzixuuPeuvOY3n25OSBtbsY3ljzq+s38ux06l2fm4nefXR543WHffNU/5xV0+s8U/CkAABIhAIAIBEKAIBEKAAAEqEAAEiEAgAgEQoAgEQoAAASoQAASIQCACDJ70jfOx5Yi0edUp7d3dFrESIiCqOiIcKriyhqvV5gtfAqABpGLcbRcM/aPRh4NSS3N3rVwd5oZO2eLPXr8+1z/TgiIqYrveai47VWxP0drzKg1dbrC755M7Z2r2r9c7YL7x7fGw3l2Y9/4yfW7tuXek1MPTeP+07bml/N9es5nXq/j7tt/VgenunnOyLi5ORUnj2/1es2VDwpAAASoQAASIQCACARCgCARCgAABKhAABIhAIAIBEKAIBEKAAAEqEAAEiEAgAgyeUgh8O+t3g9lme7ba9zZqe7I8+uFk5PUsRmq3c27e8fWLvrWu96WVdeXm82XgfKzu6uPPviYmXt/vLbG3n2YqKf74iIuTH+dl/vD4qI+Ff/4sfW/IO7+jn8D7/8ytr9V1+8kmfL7dra3Wro9+FkfGHtnk/1e2U49LqMotK7wyIiej19f6fn3Ss7hb67rLx7/K2H9+TZ4dXE2q3gSQEAkAgFAEAiFAAAiVAAACRCAQCQCAUAQCIUAACJUAAAJEIBAJAIBQBAkvslTg6PrMWLK712oVF4NRfTuV5dsVh7r5i3Cv119/mmsnY7CbzYeNUF+wcja35d6VUHXz17Ye2+utXPS93qWLubTf0sjnre9TlpeZUBvSu90uEHozNr98tD/XOej19bu1dz/d765PPPrd2NcivPbgbePRt7p958Q/+7srenV+dERAy3+vdnufaqdur1rTz76Hhg7VbwpAAASIQCACARCgCARCgAABKhAABIhAIAIBEKAIBEKAAAEqEAAEiEAgAgEQoAgCSXgxzcObYWH+z25dlGo23tHt9ey7Ob2dTa3aj0vpxt6D0vERF1W+9i2d3tWbs34c3//Vd6p81sNbN293pdfbbj9V71B3pHzUHT67365Rfn1ny51o99ted1Hx0f6NezCK9DaFPqvWTz9cLaPZvrnUDr0rs+hdkHFoU+2m4YwxFRN/SOtHbLu8fLld6pVRsdZiqeFAAAiVAAACRCAQCQCAUAQCIUAACJUAAAJEIBAJAIBQBAIhQAAIlQAAAkQgEAkPRSDrOfqGh7845uT9+9EwNrd8vIyUbDy9SN0ZXU7e9Zuy9fTaz5+aXeH/XuodertNKrdaJndBlFRLz/3n15tuEcSESUTe+evTU6uFrNG2v3sKPft0cH71m73/vBW/Ls19/9tbX7V58/l2c7Lb3jJyKirr0es7I0/ry1Otbudke/V7ZbryNta5Q2FcX3/7ueJwUAQCIUAACJUAAAJEIBAJAIBQBAIhQAAIlQAAAkQgEAkAgFAEAiFAAASX4PfLHcWIuLzcKYLq3ds9mtPLveeLlXNvRKh+ncq5a4NebvP9Rf0Y+IqEvvWN6+o79K/949r/5hvtR333/ykbW7U+vVFdc33j3b3z+y5uNNUx59eHbXWj2ezeTZd//ZD6zdowO9WmR08IG1+/pCvw+vb7zqj7ZR/RER0ai78uxmW1m7neaKauP9fWvoX5+o69raLf3/3/tGAMCvLUIBAJAIBQBAIhQAAIlQAAAkQgEAkAgFAEAiFAAAiVAAACRCAQCQCAUAQJILdqrC6wapK73vw+3v6Pf68uzuUO95iYh4caF3Nn397MLa3Wrrn7Nz/sLavTz3juUHJ3qf0R/+gdet8+XzK3l2eP/Y2n3n6EyefX1xbu3e3ze7dbb6Oew09J6kiIjXF8/l2VZvbO2+GL+UZ5+/nFq72239+7Y/MgqEImKx8P5O1C39N2/hFA5FxNboSmoU3u6ioR939f1XH/GkAAD4PwgFAEAiFAAAiVAAACRCAQCQCAUAQCIUAACJUAAAJEIBAJAIBQBAkmsu9vd3rcVlS6+5mE6X1u56o79ifjO5sXZ/+51ejTCdehUA/Z6ewS+/vrV2n/Y61vz9+2/Ls/v33rF2tydGfUFPr4qIiHjw0e/qq1/pVREREf3SqwqpQr9vZzPvHr+7o9d/rCuvLqIY6N/lB4N71u7hvl5DMnnzytr9+vyNNb8p9HtruV5Zu6Oh90sMuj1r9Xqh/11pd7zvj4InBQBAIhQAAIlQAAAkQgEAkAgFAEAiFAAAiVAAACRCAQCQCAUAQCIUAACJUAAAJLn7aDL2ekda64k82y7MbGoax9E0hiNiPtW7kg6GA2v3/kDvQFlce91HJ/eOrPn7H/6+PPt3z9bW7s+/0Oc/vnto7R6P9d2n731k7W7E3Jpfr/SupP3a6ye6fa1/3/rrjbX77qF+zsdV19rd/vBAnl2MX1q7/8d//nNr/tlT/fo07Q6hQp5c6DVJERGxMX6rNzbetZd2fu8bAQC/tggFAEAiFAAAiVAAACRCAQCQCAUAQCIUAACJUAAAJEIBAJAIBQBAkmsumvpb3RERUS2m8mxtvDIeEdGIUj+Owqu5uDbeGr+99d5fr1d6RcPdPa9C43d+9jNr/sH7P5Vn/+Of/ntr99lgV55trhfW7udffakfx7u/Ye3uHT225ge1XuUyv3pt7e5v9bqI9cKr57ic6PP7x+9Yu4/OHsmzi+nI2t3wxqPqLOXZouH9Ddps9O9yUVbW7qLW58tS/hMu40kBAJAIBQBAIhQAAIlQAAAkQgEAkAgFAEAiFAAAiVAAACRCAQCQCAUAQCIUAABJLs4ovJqfqDZ6iVDR8LKpZYzXC6PMKCKKrT57eLRj7T7b0TubfusnT6zdH3ysdxlFRFy/1rupuuWNtfvdBw/k2a1zwiPi7ORYni2X+vmOiJiP9T6biIh1qe/fLLyOmir0/qgvnz+zdv/t3/1Cnv34p945OTo7kmdvJ14fVNv7usWdR3p/2Nb8G1StjX4io/MsIuLmYizPribmSRHwpAAASIQCACARCgCARCgAABKhAABIhAIAIBEKAIBEKAAAEqEAAEiEAgAgEQoAgCQXsmxLvesjImKx0jttOgO95yUiotVqy7PNhtc78vjsQJ7t9b1MffT2Q3n2o9/7mbX77vsfWvN/81d/Ks++9VA/JxERZz/8kTzbOX7P2t3a2ZNn50u93ykiYnE7sebPXzyVZ6/PvX6iajOXZ/vDnrX7zh39+/P0xSfW7tO79+XZcu5dn3qxsuaL2bU8W9UL71iMMrh+Vz/fERGdM33+tltYuxU8KQAAEqEAAEiEAgAgEQoAgEQoAAASoQAASIQCACARCgCARCgAABKhAABIcs1FuymPRkTE9UR/Tb9aeq9q93f68myzob+OHhFxcrQjzz59ObZ2v/dbfyTPPviRPvu/eVUUm8lMnt0b6tUSERHHT34sz85ah9buTz/5a3l2tdA/Y0TE7e3Ymr98/p0826y8upVeT/++3X9Hr5aIiPjwyWN5tmwOrN3t5r4+29lYu1vLpTU///a5POvW+JTGz+lps2nt3jnSz/npvSNrt4InBQBAIhQAAIlQAAAkQgEAkAgFAEAiFAAAiVAAACRCAQCQCAUAQCIUAACJUAAAJLlgZbXwekd2unp3S9HzukHajVKerSt9NiKiv6sfyx//mz+2dn/8L/9Qnh3dObV2n3/199Z80ziH48mNtfvim/8lz76YeJ0zf/FnfybP7vbb1u7lamrNn53qnVCjodch9PWzp/Ls2riWERGH9x7Js09+9NvW7qi68ujV+Jm1em52pF0v9PNS1F6323KxlWentde/Vk/1v7Uf7FurJTwpAAASoQAASIQCACARCgCARCgAABKhAABIhAIAIBEKAIBEKAAAEqEAAEjyu93beu1t3ur1BUWpvzIeEVHWG3134b1i3uuO5Nkf/7ZXAdBt67ULn/3NJ9bu6xdfWvOrlf4q/eT6ytr99IvP5Nlp3bd2tyv9uHdbXn3KqOdVURwf6DUXL89fWbvLjX6PzydePcfTr78zpj+1dk+nE3m21/K+m2X3xJp/U+rf5X6/Z+3eGer3bb+lV39EREzmt/JsufUqThQ8KQAAEqEAAEiEAgAgEQoAgEQoAAASoQAASIQCACARCgCARCgAABKhAABIhAIAIMndRxFeP9G21LuSWu0da3dV6r1K6/C6QU73DuTZ//Ln/8nafXiq98ic3H1o7V7Pb6z5dlvvY9kd6B0yERGtht45NDD6oCIizk6O5NnF5Nra3W96HTVvLi7l2c1av2cjIoY9vVtnPfW6j/7hk1/Isy9/9bm1e1Uu9OG2101VGfdVRMTggdFlNfC63RpdvYOrZ/YTHYR+7T/44TvWbgVPCgCARCgAABKhAABIhAIAIBEKAIBEKAAAEqEAAEiEAgAgEQoAgEQoAACSXHOx3RbW4k5LfyW91/IqNKKhH0vdNF51j4jteiPPXl6+snZPL/T5/ubW2r0NrwLg8ECvi9i/d2ztLquVPPv8hXcO66jl2UbDaHGJiHXp1RE0C72iY9DzqlxK4yvRdIYjIgr9HFZrrz6lYfyduJ17NSTrrlGhERHDe/p9OOuPrd2TrV6LsZx5v72PRu/Ks3eM2hcVTwoAgEQoAAASoQAASIQCACARCgCARCgAABKhAABIhAIAIBEKAIBEKAAAEqEAAEhyOUyj6FqLe92+PFuH1zkz6Os9MoPhHWv3fLOUZ4+GHWt3y/ic65tza/e24R3LvK335ZyevuMdy1rvhXn/wwfW7p//9/8mz67rubW7XXj9Xoupvn80HFm7Oy29t6lZeN1H06V+j3/90usnGo/1e3xVzKzdx0+837D39/W/Qeva+/5cX+rXvrPUO7IiIgb39T6jxbyydit4UgAAJEIBAJAIBQBAIhQAAIlQAAAkQgEAkAgFAEAiFAAAiVAAACRCAQCQ5HfpOy0vP+arlTzb7A2s3dumXrkx3yys3c12Lc92O/pr9BER7bb+OTs7e9buvZF3Dl9d6DUa8/teFcXJw8fy7PPXl9buH/7OP5dnpxcvrN1fff6pNT+bjuXZVtO7D/f29FqMIryai5fP9fPy3bc31u5GV78PR6d6XU1ExPGhVxVSGHUexZX3/Tm41mtI7p8cWrsf7Ovfty8+e2Xt/tm//qdneFIAACRCAQCQCAUAQCIUAACJUAAAJEIBAJAIBQBAIhQAAIlQAAAkQgEAkAgFAECSCzxOj7382Lx5I88uKq+7ZTbTZ+tGZe1utfROk9HoyNrdabfl2cXs1trdb+vHHRERa33+Fz//ubX63ff1XqVnz7zulkajkGd3uvr5johoGp1aERH9vt6XM5t63UeLhT5flmtr925f/5wf/+YTa3dvqPcTlc3S2l1t5tb84qnefdSY9KzdJztDefY3n/zQ271/Ks/+8uXX1m4FTwoAgEQoAAASoQAASIQCACARCgCARCgAABKhAABIhAIAIBEKAIBEKAAAEqEAAEhyAc5bDzvW4r1C7xL54qnXaXJ+Ucuz68rrs9nd1TuBZvMba3e1ncqzTTOvry70rqmIiMlU751ZbrzP2az1+eHugbX7/NWVPPtspnffRERsa71XKSLi9Fjvviq2G2v39fhanu0OvHt8f0/v7ek0vftwtTa6xlpeN9Vs5R3LeqrvH2y93Y8fnsmz9868jrSnz/TusDcX3t9OBU8KAIBEKAAAEqEAAEiEAgAgEQoAgEQoAAASoQAASIQCACARCgCARCgAAJLc6TA68F5JXxivXx+cNK3dMdiRRy/PV9bq5Xotz7Y6I2u3sTq2G6MuICI2lfc5bxZ6jcKg79UoLOd6vcRieWntXhvnpTLPYV179+H0Vr/HR6O+tXs02pNnFwuv6uDyjX7td3cH1u6iof/OLEq9riYiotPyzmFXb9qJTse79o8eP5JnF3Pvc/7lX34mz/7Pz19buxU8KQAAEqEAAEiEAgAgEQoAgEQoAAASoQAASIQCACARCgCARCgAABKhAABIhAIAIMndR62ePBoREb1RR5493PWyqbXQe37a/a21+/ba+JyVd9z93om+uu0dd7UaW/OdHf1ztlv6tYyIaDb1bqpV7X3O9UYvkKrrwtpdeBU1Ua/1jqdKH42IiHbL6BrreN1U42u9+2ix3li79/b1PrCW0ZMUEdEw78N5lPLs+eXE2n091XdPZjfW7v/6F7+SZ8+92isJTwoAgEQoAAASoQAASIQCACARCgCARCgAABKhAABIhAIAIBEKAIBEKAAAktx1MJ0ar91HRDR35dHdgdcB0O7rfQSDbs/avben1y5MbxfW7untuT47r6zdm6U3P+wcybO9tnfty5VeQ9Jqeb9LOsZ4u9u0dheFdyw7u3pVSMNriYmy0msUOn1v+WhfryG5uvLqHyZGbcnoUL8HIyLmpV5xEhHxD9+8kWd/9bdPrd2nh3qdx+kD/XxHRERDP4d39obebuW//943AgB+bREKAIBEKAAAEqEAAEiEAgAgEQoAgEQoAAASoQAASIQCACARCgCARCgAAJJcmvLsW2/xaqx3Dg2P9Z6XiIhefyPP7ukVTBERcXio98hMZ3Nr93isz1+/6Vi7r/Wal4iIaG71XqBtrXdNRURUldHDtPU6m5xfMUWjsHY3W16H0KLSj6b2bvFob/V7vJxfWburhX4fVi2v92o81XevvUsfV2bX2Ddf6F+K8ZuZtXs90w/+bO/M2v3B2/flWfOUSHhSAAAkQgEAkAgFAEAiFAAAiVAAACRCAQCQCAUAQCIUAACJUAAAJEIBAJDk9/qr9h1r8abzE3l2tV1ZuxvlpTzb2/OqDvaP9XqOg4bXXXA438qz46u+tXt8qddWREQsZnqlQ1V6lRtR6781tqV+TiIiloulPNvpeMfdbHnncLLUj30x1Y87IqJdr+XZYWNo7d42buXZzcar/ugO9EqUXrtr7d7v6OckIuLd2Jdnf/TRwNr9/ocfybOPHj+2dv/uT/WqkGcvptZuBU8KAIBEKAAAEqEAAEiEAgAgEQoAgEQoAAASoQAASIQCACARCgCARCgAABKhAABIRV3XelkJAOD/azwpAAASoQAASIQCACARCgCARCgAABKhAABIhAIAIBEKAIBEKAAA0j8Cs+jjz4w54nYAAAAASUVORK5CYII=",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "def show_torch_image(img):\n",
    "    img = img.permute(1, 2, 0)\n",
    "    img = img.numpy().astype(np.uint8)\n",
    "\n",
    "    plt.imshow(img)\n",
    "    plt.axis('off')\n",
    "    plt.show()\n",
    "\n",
    "sample_output, z_e, z_quantized = model(x_train[0].unsqueeze(0))\n",
    "print(sample_output.shape)\n",
    "show_torch_image(255*sample_output.squeeze(0).detach().cpu())\n",
    "show_torch_image(255 * x_train[0].cpu())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

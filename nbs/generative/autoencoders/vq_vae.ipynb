{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Vector Quantized Variational Autoencoders (VQ-VAEs)\n",
    "\n",
    "Rather than computing a continuous latent representation of the input, in VQ-VAEs we compute a discrete latent representation. Here, our encoder output is discretized with respect to a learned discrete set of embeddings we refer to as a codebook.\n",
    "\n",
    "The goal here is to tackle the smoothing problem noticed in general VAEs, as well as to reduce computational complexity. We can then use the (encoder + codebook) as a tokenizer for different types of transformers."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "\n",
    "from vision.resnet import ResBlock"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device(\"mps\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "class VQVAE(nn.Module):\n",
    "    def __init__(\n",
    "        self,\n",
    "        n_channels: int,\n",
    "        latent_dim: int,\n",
    "        codebook_size: int,\n",
    "    ):\n",
    "        super().__init__()\n",
    "        \n",
    "        self.latent_dim = latent_dim\n",
    "        \n",
    "        self.encoder = nn.Sequential(\n",
    "            nn.Conv2d(n_channels, latent_dim, kernel_size=3, stride=2, padding=1),\n",
    "            nn.ReLU(),\n",
    "            nn.BatchNorm2d(latent_dim),\n",
    "            nn.Conv2d(latent_dim, latent_dim, kernel_size=3, stride=2, padding=1),\n",
    "            nn.ReLU(),\n",
    "            ResBlock(latent_dim, latent_dim, nn.ReLU),\n",
    "            ResBlock(latent_dim, latent_dim, nn.ReLU),\n",
    "        )\n",
    "\n",
    "        self.codebook = nn.Parameter(\n",
    "            torch.randn(codebook_size, latent_dim) * 0.02, \n",
    "            requires_grad=True\n",
    "        )\n",
    "        \n",
    "        self.decoder = nn.Sequential(\n",
    "            ResBlock(latent_dim, latent_dim, nn.ReLU),\n",
    "            ResBlock(latent_dim, latent_dim, nn.ReLU),\n",
    "            nn.ConvTranspose2d(latent_dim, latent_dim, kernel_size=1),\n",
    "            nn.ReLU(),\n",
    "            nn.BatchNorm2d(latent_dim),\n",
    "            nn.ConvTranspose2d(latent_dim, latent_dim, kernel_size=3, stride=2, padding=1, output_padding=1),\n",
    "            nn.ReLU(),\n",
    "            nn.BatchNorm2d(latent_dim),\n",
    "            nn.ConvTranspose2d(latent_dim, n_channels, kernel_size=3, stride=2, padding=1, output_padding=1),\n",
    "            nn.Sigmoid(),\n",
    "        )\n",
    "        \n",
    "    def forward(self, x: torch.Tensor) -> torch.Tensor:\n",
    "        \"\"\"\n",
    "        Forward pass through the VAE.\n",
    "\n",
    "        Args:\n",
    "            x: input data\n",
    "\n",
    "        Returns:\n",
    "            x_hat: reconstructed data\n",
    "        \"\"\"\n",
    "        z_encoder = self.encoder(x)\n",
    "        z_quantized = self._quantize_encoder_output(z_encoder)\n",
    "        z_q_st = z_encoder + (z_quantized - z_encoder).detach()\n",
    "        return self.decoder(z_q_st), z_encoder, z_quantized\n",
    "    \n",
    "    def _quantize_encoder_output(self, z_e: torch.Tensor) -> torch.Tensor:\n",
    "        \"\"\"\n",
    "        Quantizing the encoded tensor by snapping its elements to the closest codebook \n",
    "        entry.\n",
    "\n",
    "        Args:\n",
    "            z_e: encoded representation\n",
    "\n",
    "        Returns:\n",
    "            z_q: quantized representation\n",
    "        \"\"\"\n",
    "        batch_size, latent_dim, h, w = z_e.shape\n",
    "        encoded = z_e.permute(0, 2, 3, 1).reshape(batch_size*h*w, latent_dim)\n",
    "        quantized = self.codebook[torch.argmin(torch.cdist(encoded, self.codebook), dim=1)]\n",
    "        z_q = quantized.reshape(batch_size, h, w, latent_dim).permute(0, 3, 1, 2)\n",
    "        return z_q"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Input shape: torch.Size([2, 3, 64, 64])\n",
      "Running forward pass...\n",
      "Output shape: torch.Size([2, 3, 64, 64])\n",
      "z_e.shape: torch.Size([2, 128, 16, 16]), z_quantized.shape: torch.Size([2, 128, 16, 16])\n"
     ]
    }
   ],
   "source": [
    "# Create dummy tensors and model for testing\n",
    "batch_size = 2\n",
    "n_channels = 3\n",
    "height = 64\n",
    "width = 64\n",
    "latent_dim = 128\n",
    "codebook_size = 256\n",
    "\n",
    "dummy_input = torch.randn(batch_size, n_channels, height, width)\n",
    "\n",
    "dummy_model = VQVAE(\n",
    "    latent_dim=latent_dim,\n",
    "    n_channels=n_channels,\n",
    "    codebook_size=codebook_size\n",
    ")\n",
    "\n",
    "print(\"Input shape:\", dummy_input.shape)\n",
    "print(\"Running forward pass...\")\n",
    "x_hat, z_e, z_quantized = dummy_model(dummy_input)\n",
    "print(f\"Output shape: {x_hat.shape}\")\n",
    "print(f\"z_e.shape: {z_e.shape}, z_quantized.shape: {z_quantized.shape}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Objective Function\n",
    "\n",
    "Our objective function consists of 3 terms:\n",
    "\n",
    "![VQ-VAE Loss Function](images/vq_vae_loss.png)\n",
    "\n",
    "1. Reconstruction Loss: Ensures the decoded output matches the input\n",
    "2. Codebook Loss: Keeps the codebook entries close to the encoded representations  \n",
    "3. Commitment Loss: Prevents the encoder from growing too large\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "def validate(\n",
    "    model: nn.Module,\n",
    "    recon_loss_fn: nn.Module,\n",
    "    cb_loss_fn: nn.Module,\n",
    "    commit_loss_fn: nn.Module,\n",
    "    valid_dl: DataLoader,\n",
    "    beta: float = 1.\n",
    "):\n",
    "    model.eval()\n",
    "    with torch.no_grad():\n",
    "        tot_loss = 0.\n",
    "        tot_recon_loss = 0.\n",
    "        tot_codebook_loss = 0.\n",
    "        tot_commit_loss = 0.\n",
    "        num_batches = 0\n",
    "        for xb, _ in valid_dl:\n",
    "            x_hat, z_e, z_quantized = model(xb)\n",
    "            recon_loss = recon_loss_fn(x_hat, xb)\n",
    "            codebook_loss = cb_loss_fn(z_quantized, z_e.detach())\n",
    "            commit_loss = commit_loss_fn(z_e, z_quantized.detach())\n",
    "            loss = recon_loss + codebook_loss + (beta * commit_loss)\n",
    "            \n",
    "            tot_loss += loss.item()\n",
    "            tot_recon_loss += recon_loss.item()\n",
    "            tot_codebook_loss += codebook_loss.item()\n",
    "            tot_commit_loss += commit_loss.item()\n",
    "            num_batches += 1\n",
    "    \n",
    "    tot_loss /= num_batches\n",
    "    tot_recon_loss /= num_batches\n",
    "    tot_codebook_loss /= num_batches\n",
    "    tot_commit_loss /= num_batches\n",
    "\n",
    "    return tot_loss, tot_recon_loss, tot_codebook_loss, tot_commit_loss\n",
    "\n",
    "def kl_loss_func(mu, logvar):\n",
    "    # Clamp logvar for numerical stability\n",
    "    logvar = torch.clamp(logvar, -10, 10)\n",
    "    \n",
    "    kl_loss = -0.5 * torch.sum(1 + logvar - mu.pow(2) - logvar.exp())\n",
    "    return kl_loss / (mu.size(0) * mu.size(1)) # normalize to prevent explosion\n",
    "\n",
    "def fit(\n",
    "    epochs: int, \n",
    "    model: nn.Module,\n",
    "    recon_loss_fn: nn.Module,\n",
    "    cb_loss_fn: nn.Module,\n",
    "    commit_loss_fn: nn.Module,\n",
    "    opt: torch.optim.Optimizer, \n",
    "    scheduler: torch.optim.lr_scheduler.LRScheduler,\n",
    "    train_dl: DataLoader, \n",
    "    valid_dl: DataLoader,\n",
    "    beta: float = 1,\n",
    "    grad_clip: float = 1.0\n",
    "):\n",
    "    for epoch in range(epochs):\n",
    "        print(f\"Epoch {epoch+1}/{epochs}\")\n",
    "        model.train()\n",
    "        for xb, _ in train_dl:\n",
    "            xb = xb.to(device)\n",
    "            x_hat, z_e, z_quantized = model(xb)\n",
    "            recon_loss = recon_loss_fn(x_hat, xb)\n",
    "            codebook_loss = cb_loss_fn(z_quantized, z_e.detach())\n",
    "            commit_loss = commit_loss_fn(z_e, z_quantized.detach())\n",
    "            loss = recon_loss + codebook_loss + (beta * commit_loss)\n",
    "            \n",
    "            opt.zero_grad()\n",
    "            loss.backward()\n",
    "            torch.nn.utils.clip_grad_norm_(model.parameters(), grad_clip)\n",
    "            opt.step()\n",
    "            scheduler.step()\n",
    "\n",
    "        total_loss, recon_loss, codebook_loss, commit_loss = validate(\n",
    "            model, recon_loss_fn, cb_loss_fn, commit_loss_fn, valid_dl, beta\n",
    "        )\n",
    "        print(f\"Validation loss: {total_loss:.6f}\")\n",
    "        print(f\"Reconstruction loss: {recon_loss:.6f}\")\n",
    "        print(f\"Codebook loss: {codebook_loss:.6f}\")\n",
    "        print(f\"Commit loss: {commit_loss:.6f}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "import numpy as np\n",
    "import torch\n",
    "\n",
    "\n",
    "all_batches_data = []\n",
    "all_batches_labels = []\n",
    "\n",
    "for i in range(1, 6):\n",
    "    with open(f'data/cifar-10-batches-py/data_batch_{i}', 'rb') as f:\n",
    "        dataset_dict = pickle.load(f, encoding='bytes')\n",
    "        all_batches_data.append(dataset_dict[b'data'])\n",
    "        all_batches_labels.append(dataset_dict[b'labels'])\n",
    "\n",
    "stacked_data = np.vstack(all_batches_data)\n",
    "stacked_labels = np.hstack(all_batches_labels)\n",
    "data = torch.tensor(stacked_data, dtype=torch.float32).view(-1, 3, 32, 32).to(device) / 255.\n",
    "labels = torch.tensor(stacked_labels, dtype=torch.long).to(device)\n",
    "\n",
    "split_idx = int(0.8 * len(data))\n",
    "\n",
    "x_train, x_valid = data[:split_idx], data[split_idx:]\n",
    "y_train, y_valid = labels[:split_idx], labels[split_idx:]\n",
    "\n",
    "class CIFARCustomDataset(Dataset):\n",
    "    def __init__(self, x, y):\n",
    "        self.x = x\n",
    "        self.y = y\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.x)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        return self.x[idx], self.y[idx]\n",
    "\n",
    "train_ds = CIFARCustomDataset(x_train, y_train)\n",
    "valid_ds = CIFARCustomDataset(x_valid, y_valid)\n",
    "\n",
    "train_dl = DataLoader(train_ds, batch_size=32, shuffle=True)\n",
    "valid_dl = DataLoader(valid_ds, batch_size=32, shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n"
     ]
    }
   ],
   "source": [
    "model = VQVAE(\n",
    "    n_channels=3,\n",
    "    latent_dim=256,\n",
    "    codebook_size=128,\n",
    ")\n",
    "\n",
    "recon_loss_fn = nn.MSELoss()\n",
    "cb_loss_fn = nn.MSELoss()\n",
    "commit_loss_fn = nn.MSELoss()\n",
    "# Reduce learning rate for codebook specifically\n",
    "opt = torch.optim.AdamW([\n",
    "    {'params': [p for n, p in model.named_parameters() if 'codebook' not in n], 'lr': 1e-4},\n",
    "    {'params': [model.codebook], 'lr': 1e-5}  # lower LR for codebook\n",
    "])\n",
    "\n",
    "model.to(device)\n",
    "\n",
    "scheduler = torch.optim.lr_scheduler.CosineAnnealingLR(opt, T_max=100)\n",
    "\n",
    "fit(50, model, recon_loss_fn, cb_loss_fn, commit_loss_fn, opt, scheduler, train_dl, valid_dl, beta=0.5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([1, 3, 32, 32])\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "def show_torch_image(img):\n",
    "    img = img.permute(1, 2, 0)\n",
    "    img = img.numpy().astype(np.uint8)\n",
    "\n",
    "    plt.imshow(img)\n",
    "    plt.axis('off')\n",
    "    plt.show()\n",
    "\n",
    "sample_output, z_e, z_quantized = model(x_train[0].unsqueeze(0))\n",
    "print(sample_output.shape)\n",
    "show_torch_image(255*sample_output.squeeze(0).detach().cpu())\n",
    "show_torch_image(255 * x_train[0].cpu())"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

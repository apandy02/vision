{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Vector Quantized Variational Autoencoders (VQ-VAEs)\n",
    "\n",
    "Rather than computing a continuous latent representation of the input, in VQ-VAEs we compute a discrete latent representation. Here, our encoder output is discretized with respect to a learned discrete set of embeddings we refer to as a codebook.\n",
    "\n",
    "The goal here is to tackle the smoothing problem noticed in general VAEs, as well as to reduce computational complexity. We can then use the (encoder + codebook) as a tokenizer for different types of transformers."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 194,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "\n",
    "from torch.utils.data import Dataset, DataLoader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 195,
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device(\"mps\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 196,
   "metadata": {},
   "outputs": [],
   "source": [
    "class VQVAE(nn.Module):\n",
    "    def __init__(\n",
    "        self,\n",
    "        input_dim: int,\n",
    "        n_channels: int,\n",
    "        latent_dim: int,\n",
    "        codebook_size: int,\n",
    "    ):\n",
    "        super().__init__()\n",
    "        \n",
    "        self.latent_dim = latent_dim\n",
    "        \n",
    "        self.encoder = nn.Sequential(\n",
    "            nn.Conv2d(n_channels, 96, kernel_size=3, stride=2, padding=1),\n",
    "            nn.ReLU(),\n",
    "            nn.BatchNorm2d(96),\n",
    "            nn.Conv2d(96, 192, kernel_size=3, stride=2, padding=1),\n",
    "            nn.ReLU(),\n",
    "            nn.BatchNorm2d(192),\n",
    "            nn.Conv2d(192, 384, kernel_size=3, stride=2, padding=1), \n",
    "            nn.ReLU(),\n",
    "            nn.BatchNorm2d(384),\n",
    "            nn.Conv2d(384, latent_dim, kernel_size=3),\n",
    "            nn.ReLU(),\n",
    "            nn.BatchNorm2d(latent_dim)\n",
    "        )\n",
    "\n",
    "        self.codebook = nn.Parameter(torch.zeros(codebook_size, latent_dim)*0.1, requires_grad=True)\n",
    "        \n",
    "        self.decoder = nn.Sequential(\n",
    "            nn.ConvTranspose2d(latent_dim, 384, kernel_size=3),\n",
    "            nn.ReLU(),\n",
    "            nn.BatchNorm2d(384),\n",
    "            nn.ConvTranspose2d(384, 192, kernel_size=3, stride=2, padding=1, output_padding=1),\n",
    "            nn.ReLU(),\n",
    "            nn.BatchNorm2d(192),\n",
    "            nn.ConvTranspose2d(192, 96, kernel_size=3, stride=2, padding=1, output_padding=1),\n",
    "            nn.ReLU(),\n",
    "            nn.BatchNorm2d(96),\n",
    "            nn.ConvTranspose2d(96, n_channels, kernel_size=3, stride=2, padding=1, output_padding=1),\n",
    "            nn.Sigmoid(),\n",
    "        )\n",
    "        \n",
    "    def forward(self, x: torch.Tensor) -> torch.Tensor:\n",
    "        \"\"\"\n",
    "        Forward pass through the VAE.\n",
    "\n",
    "        Args:\n",
    "            x: input data\n",
    "\n",
    "        Returns:\n",
    "            x_hat: reconstructed data\n",
    "        \"\"\"\n",
    "        z_encoder = self.encoder(x)\n",
    "        z_quantized = self._quantize_encoder_output(z_encoder)\n",
    "        z_q_st = z_encoder + (z_quantized - z_encoder).detach()\n",
    "        return self.decoder(z_q_st), self.codebook, z_encoder, z_quantized\n",
    "    \n",
    "    def _quantize_encoder_output(self, z_e: torch.Tensor) -> torch.Tensor:\n",
    "        \"\"\"\n",
    "        Quantizing the encoded tensor by snapping its elements to the closest codebook \n",
    "        entry.\n",
    "\n",
    "        Args:\n",
    "            z_e: encoded representation\n",
    "\n",
    "        Returns:\n",
    "            z_q: quantized representation\n",
    "        \"\"\"\n",
    "        batch_size, latent_dim, h, w = z_e.shape\n",
    "        encoded = z_e.permute(0, 2, 3, 1).reshape(batch_size*h*w, latent_dim)\n",
    "        quantized = self.codebook[torch.argmin(torch.cdist(encoded, self.codebook), dim=1)]\n",
    "        z_q = quantized.reshape(batch_size, h, w, latent_dim).permute(0, 3, 1, 2)\n",
    "        return z_q"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 197,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Input shape: torch.Size([2, 3, 64, 64])\n",
      "Running forward pass...\n",
      "Output shape: torch.Size([2, 3, 64, 64]), codebook.shape: torch.Size([512, 128])\n",
      "z_e.shape: torch.Size([2, 128, 6, 6]), z_quantized.shape: torch.Size([2, 128, 6, 6])\n"
     ]
    }
   ],
   "source": [
    "# Create dummy tensors and model for testing\n",
    "batch_size = 2\n",
    "n_channels = 3\n",
    "height = 64\n",
    "width = 64\n",
    "latent_dim = 128\n",
    "codebook_size = 512\n",
    "\n",
    "dummy_input = torch.randn(batch_size, n_channels, height, width)\n",
    "\n",
    "dummy_model = VQVAE(\n",
    "    input_dim=(n_channels, height, width),\n",
    "    latent_dim=latent_dim,\n",
    "    n_channels=n_channels,\n",
    "    codebook_size=codebook_size\n",
    ")\n",
    "\n",
    "print(\"Input shape:\", dummy_input.shape)\n",
    "print(\"Running forward pass...\")\n",
    "x_hat, codebook, z_e, z_quantized = dummy_model(dummy_input)\n",
    "print(f\"Output shape: {x_hat.shape}, codebook.shape: {codebook.shape}\")\n",
    "print(f\"z_e.shape: {z_e.shape}, z_quantized.shape: {z_quantized.shape}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Objective Function\n",
    "\n",
    "Our objective function consists of 3 terms:\n",
    "\n",
    "![VQ-VAE Loss Function](images/vq_vae_loss.png)\n",
    "\n",
    "1. Reconstruction Loss: Ensures the decoded output matches the input\n",
    "2. Codebook Loss: Keeps the codebook entries close to the encoded representations  \n",
    "3. Commitment Loss: Prevents the encoder from growing too large\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 198,
   "metadata": {},
   "outputs": [],
   "source": [
    "def validate(\n",
    "    model: nn.Module,\n",
    "    recon_loss_fn: nn.Module,\n",
    "    cb_loss_fn: nn.Module,\n",
    "    commit_loss_fn: nn.Module,\n",
    "    valid_dl: DataLoader,\n",
    "    beta: float = 1.\n",
    "):\n",
    "    model.eval()\n",
    "    with torch.no_grad():\n",
    "        tot_loss = 0.\n",
    "        tot_recon_loss = 0.\n",
    "        tot_codebook_loss = 0.\n",
    "        tot_commit_loss = 0.\n",
    "        num_batches = 0\n",
    "        for xb, _ in valid_dl:\n",
    "            x_hat, codebook, z_e, z_quantized = model(xb)\n",
    "            recon_loss = recon_loss_fn(x_hat, xb)\n",
    "            codebook_loss = cb_loss_fn(z_quantized, z_e.detach())\n",
    "            commit_loss = commit_loss_fn(z_e, z_quantized.detach())\n",
    "            loss = recon_loss + codebook_loss + (beta * commit_loss)\n",
    "            \n",
    "            tot_loss += loss.item()\n",
    "            tot_recon_loss += recon_loss.item()\n",
    "            tot_codebook_loss += codebook_loss.item()\n",
    "            tot_commit_loss += commit_loss.item()\n",
    "            num_batches += 1\n",
    "    \n",
    "    tot_loss /= num_batches\n",
    "    tot_recon_loss /= num_batches\n",
    "    tot_codebook_loss /= num_batches\n",
    "    tot_commit_loss /= num_batches\n",
    "\n",
    "    return tot_loss, tot_recon_loss, tot_codebook_loss, tot_commit_loss\n",
    "\n",
    "def kl_loss_func(mu, logvar):\n",
    "    # Clamp logvar for numerical stability\n",
    "    logvar = torch.clamp(logvar, -10, 10)\n",
    "    \n",
    "    kl_loss = -0.5 * torch.sum(1 + logvar - mu.pow(2) - logvar.exp())\n",
    "    return kl_loss / (mu.size(0) * mu.size(1)) # normalize to prevent explosion\n",
    "\n",
    "def fit(\n",
    "    epochs: int, \n",
    "    model: nn.Module,\n",
    "    recon_loss_fn: nn.Module,\n",
    "    cb_loss_fn: nn.Module,\n",
    "    commit_loss_fn: nn.Module,\n",
    "    opt: torch.optim.Optimizer, \n",
    "    train_dl: DataLoader, \n",
    "    valid_dl: DataLoader,\n",
    "    beta: float = 1,\n",
    "    grad_clip: float = 1.0\n",
    "):\n",
    "    for epoch in range(epochs):\n",
    "        print(f\"Epoch {epoch+1}/{epochs}\")\n",
    "        model.train()\n",
    "        for xb, _ in train_dl:\n",
    "            x_hat, codebook, z_e, z_quantized = model(xb)\n",
    "            recon_loss = recon_loss_fn(x_hat, xb)\n",
    "            codebook_loss = cb_loss_fn(z_quantized, z_e.detach())\n",
    "            commit_loss = commit_loss_fn(z_e, z_quantized.detach())\n",
    "            loss = recon_loss + codebook_loss + (beta * commit_loss)\n",
    "            \n",
    "            opt.zero_grad()\n",
    "            loss.backward()\n",
    "            torch.nn.utils.clip_grad_norm_(model.parameters(), grad_clip)\n",
    "            opt.step()\n",
    "\n",
    "\n",
    "        total_loss, recon_loss, codebook_loss, commit_loss = validate(\n",
    "            model, recon_loss_fn, cb_loss_fn, commit_loss_fn, valid_dl, beta\n",
    "        )\n",
    "        print(f\"Validation loss: {total_loss:.6f}\")\n",
    "        print(f\"Reconstruction loss: {recon_loss:.6f}\")\n",
    "        print(f\"Codebook loss: {codebook_loss:.6f}\")\n",
    "        print(f\"Commit loss: {commit_loss:.6f}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 199,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "import numpy as np\n",
    "import torch\n",
    "\n",
    "\n",
    "all_batches_data = []\n",
    "all_batches_labels = []\n",
    "\n",
    "for i in range(1, 6):\n",
    "    with open(f'data/cifar-10-batches-py/data_batch_{i}', 'rb') as f:\n",
    "        dataset_dict = pickle.load(f, encoding='bytes')\n",
    "        all_batches_data.append(dataset_dict[b'data'])\n",
    "        all_batches_labels.append(dataset_dict[b'labels'])\n",
    "\n",
    "stacked_data = np.vstack(all_batches_data)\n",
    "stacked_labels = np.hstack(all_batches_labels)\n",
    "data = torch.tensor(stacked_data, dtype=torch.float32).view(-1, 3, 32, 32).to(device) / 255.\n",
    "labels = torch.tensor(stacked_labels, dtype=torch.long).to(device)\n",
    "\n",
    "split_idx = int(0.8 * len(data))\n",
    "\n",
    "x_train, x_valid = data[:split_idx], data[split_idx:]\n",
    "y_train, y_valid = labels[:split_idx], labels[split_idx:]\n",
    "\n",
    "class CIFARCustomDataset(Dataset):\n",
    "    def __init__(self, x, y):\n",
    "        self.x = x\n",
    "        self.y = y\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.x)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        return self.x[idx], self.y[idx]\n",
    "\n",
    "train_ds = CIFARCustomDataset(x_train, y_train)\n",
    "valid_ds = CIFARCustomDataset(x_valid, y_valid)\n",
    "\n",
    "train_dl = DataLoader(train_ds, batch_size=32, shuffle=True)\n",
    "valid_dl = DataLoader(valid_ds, batch_size=32, shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n"
     ]
    }
   ],
   "source": [
    "model = VQVAE(\n",
    "    input_dim=(3, 32, 32),\n",
    "    n_channels=3,\n",
    "    latent_dim=128,\n",
    "    codebook_size=256,\n",
    ")\n",
    "\n",
    "recon_loss_fn = nn.MSELoss()\n",
    "cb_loss_fn = nn.MSELoss()\n",
    "commit_loss_fn = nn.MSELoss()\n",
    "opt = torch.optim.AdamW(model.parameters(), lr=3e-4, weight_decay=1e-5)\n",
    "\n",
    "model.to(device)\n",
    "\n",
    "fit(100, model, recon_loss_fn, cb_loss_fn, commit_loss_fn, opt, train_dl, valid_dl, beta=0.1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([1, 3, 32, 32])\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "def show_torch_image(img):\n",
    "    img = img.permute(1, 2, 0)\n",
    "    img = img.numpy().astype(np.uint8)\n",
    "\n",
    "    plt.imshow(img)\n",
    "    plt.axis('off')\n",
    "    plt.show()\n",
    "\n",
    "sample_output, codebook, z_e, z_quantized = model(x_train[0].unsqueeze(0))\n",
    "print(sample_output.shape)\n",
    "show_torch_image(255*sample_output.squeeze(0).detach().cpu())\n",
    "show_torch_image(255 * x_train[0].cpu())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

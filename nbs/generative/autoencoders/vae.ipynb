{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "\n",
    "\n",
    "class ConvolutionalVAE(nn.Module):\n",
    "    def __init__(\n",
    "        self,\n",
    "        input_dim: int,\n",
    "        n_channels: int,\n",
    "        conv_dim: int,\n",
    "        latent_dim: int,\n",
    "    ):\n",
    "        super().__init__()\n",
    "        \n",
    "        self.latent_dim = latent_dim\n",
    "        \n",
    "        self.encoder = nn.Sequential(\n",
    "            nn.Conv2d(n_channels, conv_dim, kernel_size=3, stride=2, padding=1),\n",
    "            nn.ReLU(),\n",
    "            nn.BatchNorm2d(conv_dim),\n",
    "            nn.Conv2d(conv_dim, 2 * conv_dim, kernel_size=3, stride=2, padding=1),\n",
    "            nn.ReLU(),\n",
    "            nn.BatchNorm2d(2 * conv_dim),\n",
    "            nn.Conv2d(2 * conv_dim, 4 * conv_dim, kernel_size=3, stride=2, padding=1), \n",
    "            nn.ReLU(),\n",
    "            nn.BatchNorm2d(4 * conv_dim),\n",
    "            nn.Flatten(),\n",
    "            nn.Linear(conv_dim * 4 * input_dim[1] // 8 * input_dim[2] // 8, 2 * latent_dim),\n",
    "        )\n",
    "        \n",
    "        self.decoder = nn.Sequential(\n",
    "            nn.Linear(latent_dim, 4 * conv_dim * input_dim[1] // 8 * input_dim[2] // 8),\n",
    "            nn.Unflatten(1, (4 * conv_dim, input_dim[1] // 8, input_dim[2] // 8)),\n",
    "            nn.ConvTranspose2d(4 * conv_dim, 2 * conv_dim, kernel_size=3, stride=2, padding=1, output_padding=1),\n",
    "            nn.ReLU(),\n",
    "            nn.BatchNorm2d(2 * conv_dim),\n",
    "            nn.ConvTranspose2d(2 * conv_dim, conv_dim, kernel_size=3, stride=2, padding=1, output_padding=1),\n",
    "            nn.ReLU(),\n",
    "            nn.BatchNorm2d(conv_dim),\n",
    "            nn.ConvTranspose2d(conv_dim, n_channels, kernel_size=3, stride=2, padding=1, output_padding=1),\n",
    "            nn.Sigmoid(),\n",
    "        )\n",
    "        \n",
    "    def sample(self, mu: torch.Tensor, logvar: torch.Tensor) -> torch.Tensor:\n",
    "        \"\"\"\n",
    "        Sample from the latent space using the reparameterization trick.\n",
    "\n",
    "        Args:\n",
    "            mu: mean of the latent space\n",
    "            logvar: log variance of the latent space\n",
    "\n",
    "        Returns:\n",
    "            z: sampled latent space\n",
    "        \"\"\"\n",
    "        std = torch.exp(0.5 * logvar)\n",
    "        eps = torch.randn_like(std)\n",
    "        return mu + eps * std\n",
    "    \n",
    "    def forward(self, x: torch.Tensor) -> torch.Tensor:\n",
    "        \"\"\"\n",
    "        Forward pass through the VAE.\n",
    "\n",
    "        Args:\n",
    "            x: input data\n",
    "\n",
    "        Returns:\n",
    "            x_hat: reconstructed data\n",
    "        \"\"\"\n",
    "        encoded = self.encoder(x)\n",
    "        mu, logvar = encoded.split(self.latent_dim, dim=1)\n",
    "        z = self.sample(mu, logvar)\n",
    "        return self.decoder(z)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "x_hat shape torch.Size([4, 3, 32, 32])\n"
     ]
    }
   ],
   "source": [
    "# Checking that dimenionality is correct\n",
    "vae = ConvolutionalVAE(\n",
    "    input_dim=(3, 32, 32),\n",
    "    n_channels=3,\n",
    "    conv_dim=96,\n",
    "    latent_dim=128,\n",
    "    batch_size=4,\n",
    ")\n",
    "\n",
    "random_data = torch.randn(4, 3, 32, 32)\n",
    "x_hat = vae(random_data)\n",
    "\n",
    "print(\"x_hat shape\", x_hat.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "So we've adjusted the architecture and added in the sampling/reparameterization trick to allow the flow of gradients. What's left?\n",
    "\n",
    "the other difference between the VAE and the AE is the loss function. our loss term consists of two parts now, reconstruction and KL\n",
    "divergence of the latent distribution from a standard normal distribution"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

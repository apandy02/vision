{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "id": "5BxCN0OW67MX"
   },
   "outputs": [],
   "source": [
    "#import modules to obtain MNIST dataset \n",
    "import torch \n",
    "import torch.nn as nn\n",
    "import torchvision\n",
    "from torchvision import transforms"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "id": "7ByW8AcZM2Rv"
   },
   "outputs": [],
   "source": [
    "#OOP Style model implementation \n",
    "class LeNet(nn.Module):\n",
    "  \n",
    "  #Initialize: Define the layers in the network \n",
    "  def __init__(self):\n",
    "    super(LeNet, self).__init__()\n",
    "    self.conv1 = nn.Sequential(nn.Conv2d(1,6,kernel_size = 5), nn.BatchNorm2d(6), nn.ReLU(), nn.AvgPool2d(kernel_size=2, stride=2))\n",
    "    self.conv2 = nn.Sequential(nn.Conv2d(6,16,kernel_size = 5), nn.BatchNorm2d(16), nn.ReLU(), nn.AvgPool2d(kernel_size=2, stride=2))\n",
    "    self.fc1 = nn.Sequential(nn.Linear(400,120)) \n",
    "    self.relu = nn.ReLU()\n",
    "    self.fc2 = nn.Sequential(nn.Linear(120, 84))\n",
    "    self.relu1 = nn.ReLU()\n",
    "    self.fc3 = nn.Sequential(nn.Linear(84, 10))\n",
    "    self.softmax = nn.Softmax()\n",
    "\n",
    "  #Using the layers initialized, build a computational graph and forward pass \n",
    "  def forward(self, x):\n",
    "    out = self.conv1(x)\n",
    "    out = self.conv2(out)\n",
    "    out = out.reshape(out.shape[0], -1)\n",
    "    out = self.fc1(out)\n",
    "    out = self.relu(out)\n",
    "    out = self.fc2(out)\n",
    "    out = self.relu1(out)\n",
    "    out = self.fc3(out)\n",
    "    return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "id": "9nlcWptA55X4"
   },
   "outputs": [],
   "source": [
    "#Loading the dataset and preprocessing\n",
    "batch_size = 128\n",
    "train_dataset = torchvision.datasets.MNIST(root = './data',\n",
    "                                           train = True,\n",
    "                                           transform = transforms.Compose([\n",
    "                                                  transforms.Resize((32,32)),\n",
    "                                                  transforms.ToTensor(),\n",
    "                                                  transforms.Normalize(mean = (0.1307,), std = (0.3081,))]),\n",
    "                                           download = True)\n",
    "test_dataset = torchvision.datasets.MNIST(root = './data',\n",
    "                                          train = False,\n",
    "                                          transform = transforms.Compose([\n",
    "                                                  transforms.Resize((32,32)),\n",
    "                                                  transforms.ToTensor(),\n",
    "                                                  transforms.Normalize(mean = (0.1325,), std = (0.3105,))]),\n",
    "                                          download=True)\n",
    "\n",
    "train_loader = torch.utils.data.DataLoader(dataset = train_dataset,\n",
    "                                           batch_size = batch_size,\n",
    "                                           shuffle = True)\n",
    "test_loader = torch.utils.data.DataLoader(dataset = test_dataset,\n",
    "                                           batch_size = batch_size,\n",
    "                                           shuffle = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "2ZMaOl9f6sCA",
    "outputId": "44b0769a-8693-4808-d526-9d7476b46da1"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0 / 10\n",
      "**********\n",
      "Current Epoch loss: 0.1473, accuracy: 93.59 %\n",
      "Epoch 1 / 10\n",
      "**********\n",
      "Current Epoch loss: 0.0856, accuracy: 98.02 %\n",
      "Epoch 2 / 10\n",
      "**********\n",
      "Current Epoch loss: 0.0101, accuracy: 98.59 %\n",
      "Epoch 3 / 10\n",
      "**********\n",
      "Current Epoch loss: 0.0411, accuracy: 98.72 %\n",
      "Epoch 4 / 10\n",
      "**********\n",
      "Current Epoch loss: 0.0387, accuracy: 98.88 %\n",
      "Epoch 5 / 10\n",
      "**********\n",
      "Current Epoch loss: 0.0080, accuracy: 99.09 %\n",
      "Epoch 6 / 10\n",
      "**********\n",
      "Current Epoch loss: 0.0354, accuracy: 99.16 %\n",
      "Epoch 7 / 10\n",
      "**********\n",
      "Current Epoch loss: 0.0438, accuracy: 99.29 %\n",
      "Epoch 8 / 10\n",
      "**********\n",
      "Current Epoch loss: 0.0039, accuracy: 99.31 %\n",
      "Epoch 9 / 10\n",
      "**********\n",
      "Current Epoch loss: 0.0693, accuracy: 99.40 %\n"
     ]
    }
   ],
   "source": [
    "#Mount model onto GPU \n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "model = LeNet().to(device)\n",
    "\n",
    "#pick loss function and optimizer \n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr = 1e-3)\n",
    "#Training loop \n",
    "for epoch in range(10):\n",
    "  print(\"Epoch {} / 10\".format(epoch))\n",
    "  print(\"*\"*10)\n",
    "  correct = 0\n",
    "  for batch_idx, (x_var, y_var) in enumerate(train_loader):\n",
    "    x_batch = x_var.to(device)\n",
    "    #print(x_batch.size())\n",
    "    y_batch = y_var.to(device)\n",
    "    y_pred = model(x_batch)\n",
    "    loss = criterion(y_pred, y_batch)\n",
    "    optimizer.zero_grad()\n",
    "    _, preds = torch.max(y_pred, 1)\n",
    "    correct += torch.sum(preds == y_batch.data)\n",
    "    accuracy = 100 * (correct.double() / len(train_loader.dataset))\n",
    "    loss.backward()\n",
    "    optimizer.step()\n",
    "  print('Current Epoch loss: {:.4f}, accuracy: {:.2f} %'.format(loss, accuracy))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "6ShboRTLChmi",
    "outputId": "f43f4dea-962f-4fff-e329-b41cfd3e21b7"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Set Accuracy: 99.06\n"
     ]
    }
   ],
   "source": [
    "#Fit model and compute accuracy in the wild (test set)\n",
    "correct = 0\n",
    "for batch_idx_test, (x_var_test, y_var_test) in enumerate(test_loader):\n",
    "  x_batch_test = x_var_test.to(device)\n",
    "  y_batch_test = y_var_test.to(device)\n",
    "  y_pred_test = model(x_batch_test)\n",
    "\n",
    "  _, preds = torch.max(y_pred_test, 1)\n",
    "  correct += torch.sum(preds == y_batch_test.data)\n",
    "\n",
    "accuracy = 100 * (correct.double() / len(test_loader.dataset))\n",
    "\n",
    "print(\"Test Set Accuracy: {:.2f}\".format(accuracy))"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [],
   "provenance": []
  },
  "gpuClass": "standard",
  "kernelspec": {
   "display_name": "Python 3",
   "name": "python3"
  },
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
